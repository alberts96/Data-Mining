{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [Riccardo Guidotti](http://kdd.isti.cnr.it/people/riccardo-guidotti)  \n",
    "**Python version:**  3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "#plt.rcParams['figure.dpi']= 300  #resolution\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_list(ts_list, attribute, ts_number=1000, time = None , formatter = None):\n",
    "    if ts_number >= len(ts_list): ts_number = len(ts_list)-1\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots()\n",
    "    for ts in ts_list[:ts_number]:\n",
    "        if time == None: index = list(ts.index.values)\n",
    "        else: index= ts[time]\n",
    "        ax.plot(index, ts[attribute])\n",
    "    ax.set_ylabel(attribute)\n",
    "    if formatter !=None:\n",
    "        date_form = DateFormatter(formatter)\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_col = 'date'\n",
    "\n",
    "attributes = ['date', 'Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio', 'Occupancy']\n",
    "\n",
    "\n",
    "df=pd.read_csv(r'../../data/datatraining.txt')\n",
    "df[time_col] =  pd.to_datetime(df[time_col], format = '%Y-%m-%d %H:%M:%S')\n",
    "df['Weekday']=df[time_col].apply(lambda x:x.weekday())\n",
    "\n",
    "mon1=df[df['Weekday']==0][attributes].copy()\n",
    "tue1=df[df['Weekday']==1][attributes].copy()  #missing part of the day\n",
    "wed1=df[df['Weekday']==2][attributes].copy() #incompleted too\n",
    "thu1=df[df['Weekday']==3][attributes].copy()\n",
    "fri1=df[df['Weekday']==4][attributes].copy()\n",
    "sat1=df[df['Weekday']==5][attributes].copy()\n",
    "sun1=df[df['Weekday']==6][attributes].copy()\n",
    "    \n",
    "weekdays1 = [thu1,fri1,sat1,sun1,mon1] #I dont want incompleted days, so wednesday and tuesday are excluded\n",
    "\n",
    "\n",
    "\n",
    "df=pd.read_csv(r'../../data/datatest2.txt')\n",
    "df[time_col] =  pd.to_datetime(df[time_col], format = '%Y-%m-%d %H:%M:%S')\n",
    "df['Weekday']=df[time_col].apply(lambda x:x.weekday())\n",
    "                                 \n",
    "mon2=df[df['Weekday']==0][attributes].copy()\n",
    "tue2=df[df['Weekday']==1][attributes].copy()  #missing part of the day\n",
    "wed2=df[df['Weekday']==2][attributes].copy() #incompleted too\n",
    "thu2=df[df['Weekday']==3][attributes].copy()\n",
    "fri2=df[df['Weekday']==4][attributes].copy()\n",
    "sat2=df[df['Weekday']==5][attributes].copy()\n",
    "sun2=df[df['Weekday']==6][attributes].copy()\n",
    "    \n",
    "weekdays2 = [thu2,fri2,sat2,sun2,mon2] #I dont want incompleted days, so wednesday and tuesday are excluded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## week list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "week_size = 144\n",
    "week_list = []\n",
    "labels = []\n",
    "\n",
    "week1 = pd.DataFrame()\n",
    "for day in weekdays1:\n",
    "    day.sort_values(time_col, inplace=True)#first of all: order\n",
    "    week1 = week1.append(day, ignore_index=True )    ##a week\n",
    "    \n",
    "    \n",
    "week1_list = []\n",
    "tmp = week1.copy() \n",
    "while(len(tmp)>=week_size):\n",
    "    ts = tmp.sample(week_size)\n",
    "    ts.sort_values(time_col, inplace=True)\n",
    "    week1_list.append(ts)\n",
    "    week_list.append(ts)\n",
    "    tmp.drop(ts.index, axis=0, inplace=True) #remove the sample just extract\n",
    "\n",
    "    \n",
    "week2 = pd.DataFrame()\n",
    "for day in weekdays2:    \n",
    "    day.sort_values(time_col, inplace=True)#first of all: order\n",
    "    week2 = week2.append(day, ignore_index=True)    ##a week\n",
    "    \n",
    "week2_list = []\n",
    "tmp = week2.copy() \n",
    "while(len(tmp)>=week_size):\n",
    "    ts = tmp.sample(week_size)\n",
    "    ts.sort_values(time_col, inplace=True)\n",
    "    week2_list.append(ts)\n",
    "    week_list.append(ts)\n",
    "    tmp.drop(ts.index, axis=0, inplace=True) #remove the sample just extract\n",
    "\n",
    "    \n",
    "random.shuffle(week_list)\n",
    "draw_list(week_list, 'CO2', 15, time = time_col ,formatter = '%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 144)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_list = []\n",
    "for temp in week_list:\n",
    "    ts = temp['Temperature'].copy()\n",
    "    ts_list.append((ts-ts.mean())/ts.std())\n",
    "\n",
    "ts_array = []\n",
    "ts_size = len(week_list[1])\n",
    "for ts in ts_list:\n",
    "    ts_array.append(np.array(ts).reshape(ts_size,))\n",
    "    \n",
    "X = np.array(ts_array)\n",
    "week1o2 = lambda ts : 0 if ts['date'][ts.index[0]].day == 12 else 1\n",
    "labels = [week1o2(ts) for ts in week_list]\n",
    "y = labels.copy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adagrad\n",
    "from tslearn.shapelets import ShapeletModel\n",
    "from tslearn.shapelets import grabocka_params_to_shapelet_size_dict\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X = scaler.fit_transform(X).reshape(X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaplet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ts 70\n",
      "ts_sz 144\n",
      "n_classes 2\n",
      "shapelet_sizes {14: 3}\n"
     ]
    }
   ],
   "source": [
    "n_ts, ts_sz = X_train.shape\n",
    "n_classes = len(set(y))\n",
    "\n",
    "# Set the number of shapelets per size as done in the original paper\n",
    "shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                       ts_sz=ts_sz,\n",
    "                                                       n_classes=n_classes,\n",
    "                                                       l=0.1,\n",
    "                                                       r=1)\n",
    "\n",
    "print('n_ts', n_ts)\n",
    "print('ts_sz', ts_sz)\n",
    "print('n_classes', n_classes)\n",
    "print('shapelet_sizes', shapelet_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model using parameters provided by the authors (except that we use\n",
    "# fewer iterations here)\n",
    "shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                        optimizer=\"sgd\",\n",
    "                        weight_regularizer=.01,\n",
    "                        max_iter=200,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 2/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 3/200\n",
      "70/70 [==============================] - 0s 557us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 4/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 5/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 6/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 7/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 8/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 9/200\n",
      "70/70 [==============================] - 0s 429us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 10/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 11/200\n",
      "70/70 [==============================] - 0s 343us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 12/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 13/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 14/200\n",
      "70/70 [==============================] - 0s 443us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 15/200\n",
      "70/70 [==============================] - 0s 343us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 16/200\n",
      "70/70 [==============================] - 0s 314us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 17/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 18/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 19/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 20/200\n",
      "70/70 [==============================] - 0s 457us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 21/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 22/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 23/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 24/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 25/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 26/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 27/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 28/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 29/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 30/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6991 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 31/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 32/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 33/200\n",
      "70/70 [==============================] - 0s 300us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 34/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 35/200\n",
      "70/70 [==============================] - 0s 343us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 36/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 37/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 38/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 39/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 40/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 41/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 42/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 43/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 44/200\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 45/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 46/200\n",
      "70/70 [==============================] - 0s 414us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 47/200\n",
      "70/70 [==============================] - 0s 343us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 48/200\n",
      "70/70 [==============================] - 0s 357us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 49/200\n",
      "70/70 [==============================] - 0s 657us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 50/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 51/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 52/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 53/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 54/200\n",
      "70/70 [==============================] - 0s 185us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 55/200\n",
      "70/70 [==============================] - 0s 215us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 56/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 57/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 58/200\n",
      "70/70 [==============================] - 0s 400us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 59/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 60/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 61/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 62/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 63/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 64/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 65/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 66/200\n",
      "70/70 [==============================] - 0s 357us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 67/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 68/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 69/200\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 70/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 71/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6990 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 72/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 73/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 74/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 75/200\n",
      "70/70 [==============================] - 0s 343us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 76/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 77/200\n",
      "70/70 [==============================] - 0s 314us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 78/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 79/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 80/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 81/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 82/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 83/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 84/200\n",
      "70/70 [==============================] - 0s 443us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 85/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 86/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 87/200\n",
      "70/70 [==============================] - 0s 314us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 88/200\n",
      "70/70 [==============================] - 0s 172us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 89/200\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 90/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 91/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 92/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 93/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 94/200\n",
      "70/70 [==============================] - 0s 400us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 95/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 96/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 97/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 98/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 99/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 100/200\n",
      "70/70 [==============================] - 0s 228us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 101/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 102/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 103/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6989 - binary_accuracy: 0.5000 - binary_crossentropy: 0.6930\n",
      "Epoch 104/200\n",
      "70/70 [==============================] - 0s 643us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 105/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 106/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 107/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 108/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 109/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 110/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 111/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 112/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 113/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 114/200\n",
      "70/70 [==============================] - 0s 428us/step - loss: 0.6989 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 115/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 116/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 117/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 118/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 119/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 120/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 121/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 122/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 123/200\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 124/200\n",
      "70/70 [==============================] - 0s 443us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 125/200\n",
      "70/70 [==============================] - 0s 514us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 126/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 127/200\n",
      "70/70 [==============================] - 0s 228us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 128/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 129/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 130/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 131/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 132/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 133/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 134/200\n",
      "70/70 [==============================] - 0s 471us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 135/200\n",
      "70/70 [==============================] - 0s 371us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 136/200\n",
      "70/70 [==============================] - 0s 457us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 137/200\n",
      "70/70 [==============================] - 0s 314us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 138/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 139/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 140/200\n",
      "70/70 [==============================] - 0s 228us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 141/200\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 142/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 143/200\n",
      "70/70 [==============================] - 0s 443us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 144/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 145/200\n",
      "70/70 [==============================] - 0s 414us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 146/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 147/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 148/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 149/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 150/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 151/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 152/200\n",
      "70/70 [==============================] - 0s 386us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 153/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 154/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 155/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 156/200\n",
      "70/70 [==============================] - 0s 300us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 157/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6988 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 158/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 159/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 160/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 161/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 162/200\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 163/200\n",
      "70/70 [==============================] - 0s 357us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 164/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 165/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 166/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6987 - binary_accuracy: 0.4857 - binary_crossentropy: 0.6930\n",
      "Epoch 167/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6987 - binary_accuracy: 0.4714 - binary_crossentropy: 0.6930\n",
      "Epoch 168/200\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 169/200\n",
      "70/70 [==============================] - 0s 314us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 170/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 171/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 172/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 173/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 174/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 175/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 176/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 177/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 178/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 179/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 180/200\n",
      "70/70 [==============================] - 0s 257us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 181/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 182/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 183/200\n",
      "70/70 [==============================] - 0s 300us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 184/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 185/200\n",
      "70/70 [==============================] - 0s 229us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 186/200\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 187/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 188/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 189/200\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 190/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 191/200\n",
      "70/70 [==============================] - 0s 186us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 192/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 193/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 194/200\n",
      "70/70 [==============================] - 0s 457us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 195/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 196/200\n",
      "70/70 [==============================] - 0s 214us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 197/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 198/200\n",
      "70/70 [==============================] - 0s 243us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 199/200\n",
      "70/70 [==============================] - 0s 300us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n",
      "Epoch 200/200\n",
      "70/70 [==============================] - 0s 200us/step - loss: 0.6987 - binary_accuracy: 0.4571 - binary_crossentropy: 0.6930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapeletModel(batch_size=256, max_iter=200, n_shapelets_per_size={14: 3},\n",
       "              optimizer='sgd', random_state=None, shapelet_length=0.15,\n",
       "              total_lengths=3, verbose=1, verbose_level=None,\n",
       "              weight_regularizer=0.01)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 367us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = shp_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.68181818 0.125     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        15\n",
      "           1       1.00      0.07      0.12        15\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.76      0.53      0.40        30\n",
      "weighted avg       0.76      0.53      0.40        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaplet-distances-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 114us/step\n"
     ]
    }
   ],
   "source": [
    "X_train2 = shp_clf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00269821, 0.00333317, 0.00388885],\n",
       "       [0.00845643, 0.00984028, 0.01106388],\n",
       "       [0.00784878, 0.0097966 , 0.01062184],\n",
       "       [0.00416938, 0.0050126 , 0.00578184],\n",
       "       [0.00191129, 0.00241136, 0.00292677],\n",
       "       [0.00234383, 0.00313029, 0.0033866 ],\n",
       "       [0.00181628, 0.00191799, 0.00251657],\n",
       "       [0.00339916, 0.0048296 , 0.00535402],\n",
       "       [0.00341293, 0.00421446, 0.00482392],\n",
       "       [0.00659102, 0.00789648, 0.00851477],\n",
       "       [0.00237628, 0.00343278, 0.00361943],\n",
       "       [0.00782139, 0.0090682 , 0.01025998],\n",
       "       [0.00367899, 0.00439218, 0.00494288],\n",
       "       [0.00344816, 0.00448906, 0.005072  ],\n",
       "       [0.00607249, 0.00730588, 0.00823576],\n",
       "       [0.00819576, 0.00990594, 0.01107259],\n",
       "       [0.00348358, 0.00457696, 0.0053727 ],\n",
       "       [0.00410394, 0.00513426, 0.0059685 ],\n",
       "       [0.00473087, 0.00549542, 0.00593797],\n",
       "       [0.00293381, 0.00336639, 0.00400996],\n",
       "       [0.0025393 , 0.00350924, 0.00374671],\n",
       "       [0.00694654, 0.00826463, 0.00920437],\n",
       "       [0.00577924, 0.00651486, 0.0074742 ],\n",
       "       [0.00489449, 0.00638084, 0.00639192],\n",
       "       [0.00325741, 0.00445386, 0.00430359],\n",
       "       [0.00292136, 0.00365339, 0.00444744],\n",
       "       [0.00745833, 0.00935608, 0.01057324],\n",
       "       [0.00515658, 0.00655758, 0.00683883],\n",
       "       [0.00688763, 0.00829028, 0.00911917],\n",
       "       [0.00470268, 0.00616386, 0.00675116],\n",
       "       [0.00527892, 0.00650003, 0.00749139],\n",
       "       [0.0069825 , 0.00797374, 0.00812776],\n",
       "       [0.00395331, 0.00494032, 0.00558396],\n",
       "       [0.00302202, 0.00387321, 0.00423764],\n",
       "       [0.00384165, 0.00471449, 0.00548167],\n",
       "       [0.00477452, 0.00614277, 0.0068134 ],\n",
       "       [0.0046832 , 0.0055677 , 0.00630589],\n",
       "       [0.00576285, 0.00716841, 0.00813136],\n",
       "       [0.00369305, 0.00478291, 0.00522687],\n",
       "       [0.01119234, 0.01306909, 0.01394383],\n",
       "       [0.0043196 , 0.00487642, 0.00582275],\n",
       "       [0.00943212, 0.01120464, 0.01242017],\n",
       "       [0.00169993, 0.00217895, 0.00286358],\n",
       "       [0.00314189, 0.00379136, 0.00450369],\n",
       "       [0.00391949, 0.00506748, 0.00509583],\n",
       "       [0.00680154, 0.00791712, 0.00851359],\n",
       "       [0.00291063, 0.00388592, 0.00454765],\n",
       "       [0.00569056, 0.00665666, 0.00680821],\n",
       "       [0.00545164, 0.00637635, 0.00716862],\n",
       "       [0.0050809 , 0.00623779, 0.00615674],\n",
       "       [0.00282321, 0.00342836, 0.0040158 ],\n",
       "       [0.00439286, 0.00577142, 0.00660728],\n",
       "       [0.00329559, 0.00408682, 0.004744  ],\n",
       "       [0.00430519, 0.00507861, 0.00581718],\n",
       "       [0.00367069, 0.00437103, 0.0050335 ],\n",
       "       [0.00531572, 0.00603014, 0.006838  ],\n",
       "       [0.00487338, 0.00573174, 0.00651033],\n",
       "       [0.00482685, 0.00612362, 0.00675314],\n",
       "       [0.00383921, 0.00472566, 0.00491817],\n",
       "       [0.00305484, 0.00382211, 0.00416831],\n",
       "       [0.00882946, 0.01068354, 0.01152868],\n",
       "       [0.00539113, 0.00681442, 0.00756049],\n",
       "       [0.00232888, 0.00272197, 0.00340015],\n",
       "       [0.00124962, 0.00134651, 0.0019026 ],\n",
       "       [0.00374025, 0.00482208, 0.00511686],\n",
       "       [0.00520034, 0.00622989, 0.00743105],\n",
       "       [0.00388558, 0.00490848, 0.00567288],\n",
       "       [0.00361605, 0.00483844, 0.0052778 ],\n",
       "       [0.00220593, 0.00284903, 0.00344155],\n",
       "       [0.00679372, 0.00782601, 0.00891135]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test2 = shp_clf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6666666666666666\n",
      "F1-score [0.72222222 0.58333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72        15\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.70      0.67      0.65        30\n",
      "weighted avg       0.70      0.67      0.65        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.43333333333333335\n",
      "F1-score [0.4516129 0.4137931]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.45        15\n",
      "           1       0.43      0.40      0.41        15\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.43      0.43      0.43        30\n",
      "weighted avg       0.43      0.43      0.43        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train2, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(values):\n",
    "    features = {\n",
    "        'avg': np.mean(values),\n",
    "        'std': np.std(values),\n",
    "        'var': np.var(values),\n",
    "        'med': np.median(values),\n",
    "        '10p': np.percentile(values, 10),\n",
    "        '25p': np.percentile(values, 25),\n",
    "        '50p': np.percentile(values, 50),\n",
    "        '75p': np.percentile(values, 75),\n",
    "        '90p': np.percentile(values, 90),\n",
    "        'iqr': np.percentile(values, 75) - np.percentile(values, 25),\n",
    "        'cov': 1.0 * np.mean(values) / np.std(values),\n",
    "        'skw': stats.skew(values),\n",
    "        'kur': stats.kurtosis(values)\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = np.array([list(calculate_features(x).values()) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33837818,  0.2518513 ,  0.06342908,  0.3225    ,  0.0475    ,\n",
       "         0.1       ,  0.3225    ,  0.5       ,  0.725     ,  0.4       ,\n",
       "         1.34356339,  0.52248366, -0.81122823],\n",
       "       [ 0.32734329,  0.23801839,  0.05665275,  0.23529412,  0.0857754 ,\n",
       "         0.16898396,  0.23529412,  0.44919786,  0.70278075,  0.2802139 ,\n",
       "         1.3752857 ,  1.18361831,  0.7067956 ],\n",
       "       [ 0.287269  ,  0.21016108,  0.04416768,  0.22964509,  0.09634656,\n",
       "         0.12526096,  0.22964509,  0.36430063,  0.57635699,  0.23903967,\n",
       "         1.36689918,  1.44724956,  1.93199367],\n",
       "       [ 0.37217771,  0.27343816,  0.07476843,  0.31217949,  0.04871795,\n",
       "         0.13685897,  0.31217949,  0.58445513,  0.76923077,  0.44759615,\n",
       "         1.36110376,  0.46659205, -0.9572542 ],\n",
       "       [ 0.3772231 ,  0.27315018,  0.07461102,  0.35220126,  0.05157233,\n",
       "         0.10062893,  0.35220126,  0.59339623,  0.75471698,  0.4927673 ,\n",
       "         1.38100986,  0.38096133, -0.99331974],\n",
       "       [ 0.36503943,  0.26672155,  0.07114039,  0.33898305,  0.05677966,\n",
       "         0.10858051,  0.33898305,  0.56525424,  0.75911017,  0.45667373,\n",
       "         1.36861617,  0.4579168 , -0.82840653],\n",
       "       [ 0.27178052,  0.23432286,  0.0549072 ,  0.20876827,  0.0605428 ,\n",
       "         0.10438413,  0.20876827,  0.36064718,  0.62160752,  0.25626305,\n",
       "         1.15985494,  1.38520426,  1.34956964],\n",
       "       [ 0.33766303,  0.2707376 ,  0.07329885,  0.22580645,  0.07548387,\n",
       "         0.13844086,  0.22580645,  0.46599462,  0.82580645,  0.32755376,\n",
       "         1.24719667,  1.01823934, -0.08215638],\n",
       "       [ 0.31288707,  0.23846316,  0.05686468,  0.24043716,  0.08014572,\n",
       "         0.16284153,  0.24043716,  0.37486339,  0.67759563,  0.21202186,\n",
       "         1.31209811,  1.34628536,  1.19333378],\n",
       "       [ 0.42259055,  0.27175063,  0.07384841,  0.41666667,  0.07295597,\n",
       "         0.17358491,  0.41666667,  0.65597484,  0.77987421,  0.48238994,\n",
       "         1.55506742,  0.16137313, -1.24795991],\n",
       "       [ 0.33847193,  0.26826837,  0.07196792,  0.29230769,  0.04871795,\n",
       "         0.08173077,  0.29230769,  0.54230769,  0.74957265,  0.46057692,\n",
       "         1.2616915 ,  0.54672496, -0.94724905],\n",
       "       [ 0.32808477,  0.26047303,  0.0678462 ,  0.22994652,  0.09336898,\n",
       "         0.1540107 ,  0.22994652,  0.44919786,  0.80534759,  0.29518717,\n",
       "         1.25957289,  1.18605327,  0.28392924],\n",
       "       [ 0.38183097,  0.27119425,  0.07354632,  0.33986928,  0.0496732 ,\n",
       "         0.14150327,  0.33986928,  0.57254902,  0.78431373,  0.43104575,\n",
       "         1.40796117,  0.3222992 , -1.05769332],\n",
       "       [ 0.30641926,  0.23643789,  0.05590288,  0.22580645,  0.07311828,\n",
       "         0.13799283,  0.22580645,  0.41935484,  0.68645161,  0.28136201,\n",
       "         1.29598203,  1.27913749,  1.0757648 ],\n",
       "       [ 0.37035012,  0.25447482,  0.06475744,  0.3225    ,  0.0725    ,\n",
       "         0.16125   ,  0.3225    ,  0.525     ,  0.76166667,  0.36375   ,\n",
       "         1.45535071,  0.55107117, -0.60551027],\n",
       "       [ 0.34551471,  0.25238631,  0.06369885,  0.29752917,  0.08030199,\n",
       "         0.14413178,  0.29752917,  0.47151682,  0.75978037,  0.32738504,\n",
       "         1.36899151,  0.90226844, -0.02286143],\n",
       "       [ 0.34946558,  0.25276404,  0.06388966,  0.28434783,  0.04956522,\n",
       "         0.15391304,  0.28434783,  0.54521739,  0.75652174,  0.39130435,\n",
       "         1.38257635,  0.54440132, -0.82098066],\n",
       "       [ 0.39493884,  0.2641637 ,  0.06978246,  0.36419753,  0.08395062,\n",
       "         0.1255144 ,  0.36419753,  0.58004115,  0.8       ,  0.45452675,\n",
       "         1.49505342,  0.35318863, -0.98545213],\n",
       "       [ 0.31397284,  0.24831967,  0.06166266,  0.22424667,  0.07498248,\n",
       "         0.14015417,  0.22424667,  0.4134548 ,  0.7470918 ,  0.27330063,\n",
       "         1.2643897 ,  1.22950752,  0.75097919],\n",
       "       [ 0.36921593,  0.26238677,  0.06884682,  0.33076923,  0.06538462,\n",
       "         0.13461538,  0.33076923,  0.56153846,  0.76730769,  0.42692308,\n",
       "         1.40714384,  0.50266023, -0.77888925],\n",
       "       [ 0.33942011,  0.25491341,  0.06498085,  0.31794872,  0.05641026,\n",
       "         0.1025641 ,  0.31794872,  0.52564103,  0.76923077,  0.42307692,\n",
       "         1.33151138,  0.59380308, -0.72569224],\n",
       "       [ 0.34207285,  0.23789292,  0.05659304,  0.3245283 ,  0.07295597,\n",
       "         0.12578616,  0.3245283 ,  0.48113208,  0.6909434 ,  0.35534591,\n",
       "         1.43792784,  0.6856898 , -0.27010641],\n",
       "       [ 0.28349716,  0.22977523,  0.05279666,  0.20876827,  0.0605428 ,\n",
       "         0.12526096,  0.20876827,  0.3894833 ,  0.57933194,  0.26422234,\n",
       "         1.23380208,  1.44145802,  1.67490725],\n",
       "       [ 0.37964856,  0.25863039,  0.06688968,  0.34067086,  0.07295597,\n",
       "         0.14779874,  0.34067086,  0.58301887,  0.75471698,  0.43522013,\n",
       "         1.46791934,  0.39520858, -0.95383061],\n",
       "       [ 0.38313079,  0.2679129 ,  0.07177732,  0.38235294,  0.05588235,\n",
       "         0.11764706,  0.38235294,  0.57352941,  0.76176471,  0.45588235,\n",
       "         1.43005724,  0.28496975, -0.96787028],\n",
       "       [ 0.36090931,  0.28023526,  0.0785318 ,  0.33333333,  0.04871795,\n",
       "         0.1025641 ,  0.33333333,  0.59615385,  0.76923077,  0.49358974,\n",
       "         1.28787973,  0.45552438, -1.07810171],\n",
       "       [ 0.31102369,  0.21654241,  0.04689062,  0.25265957,  0.08297872,\n",
       "         0.17606383,  0.25265957,  0.42553191,  0.58148936,  0.24946809,\n",
       "         1.43631767,  1.17826199,  1.24383512],\n",
       "       [ 0.41436722,  0.2782583 ,  0.07742768,  0.37184595,  0.07702523,\n",
       "         0.12948207,  0.37184595,  0.61553785,  0.80301018,  0.48605578,\n",
       "         1.48914597,  0.28486946, -1.07326743],\n",
       "       [ 0.29252874,  0.2274454 ,  0.05173141,  0.20661157,  0.08057851,\n",
       "         0.12396694,  0.20661157,  0.4149449 ,  0.59504132,  0.29097796,\n",
       "         1.28614929,  1.30456087,  1.14218449],\n",
       "       [ 0.31817105,  0.25720963,  0.06615679,  0.21097046,  0.06118143,\n",
       "         0.13370253,  0.21097046,  0.44462025,  0.79324895,  0.31091772,\n",
       "         1.23701065,  1.13085533,  0.27726395],\n",
       "       [ 0.32041593,  0.25548789,  0.06527406,  0.23138298,  0.09819149,\n",
       "         0.13297872,  0.23138298,  0.44680851,  0.78297872,  0.31382979,\n",
       "         1.25413352,  1.28001426,  0.662934  ],\n",
       "       [ 0.35490825,  0.26798909,  0.07181815,  0.2750533 ,  0.08528785,\n",
       "         0.14712154,  0.2750533 ,  0.50439765,  0.82803838,  0.35727612,\n",
       "         1.32433842,  0.83990184, -0.2999268 ],\n",
       "       [ 0.31623264,  0.24523781,  0.06014159,  0.24431818,  0.06965909,\n",
       "         0.12357955,  0.24431818,  0.44602273,  0.675     ,  0.32244318,\n",
       "         1.28949379,  1.08728204,  0.46722975],\n",
       "       [ 0.30687919,  0.24048181,  0.0578315 ,  0.23404255,  0.07553191,\n",
       "         0.12765957,  0.23404255,  0.42553191,  0.70914894,  0.29787234,\n",
       "         1.27610143,  1.1767294 ,  0.59205568],\n",
       "       [ 0.30126473,  0.24018129,  0.05768705,  0.20590254,  0.08030199,\n",
       "         0.13383665,  0.20590254,  0.41437886,  0.6704873 ,  0.28054221,\n",
       "         1.25432221,  1.35499338,  1.21678705],\n",
       "       [ 0.35480999,  0.26319819,  0.06927329,  0.29447853,  0.0791411 ,\n",
       "         0.12269939,  0.29447853,  0.5398773 ,  0.7607362 ,  0.41717791,\n",
       "         1.34807151,  0.67506337, -0.72950649],\n",
       "       [ 0.29463551,  0.22164062,  0.04912456,  0.22555096,  0.09297521,\n",
       "         0.15289256,  0.22555096,  0.40418388,  0.62706612,  0.25129132,\n",
       "         1.32933899,  1.29697352,  1.19350981],\n",
       "       [ 0.28957772,  0.24300517,  0.05905152,  0.19514768,  0.0664557 ,\n",
       "         0.11075949,  0.19514768,  0.37236287,  0.69936709,  0.26160338,\n",
       "         1.19165247,  1.40396244,  1.2389819 ],\n",
       "       [ 0.41912838,  0.27586527,  0.07610165,  0.42051282,  0.04871795,\n",
       "         0.17371795,  0.42051282,  0.64391026,  0.79057692,  0.47019231,\n",
       "         1.51932277,  0.17106551, -1.13422977],\n",
       "       [ 0.39651366,  0.26080466,  0.06801907,  0.33902439,  0.09512195,\n",
       "         0.17073171,  0.33902439,  0.58963415,  0.7804878 ,  0.41890244,\n",
       "         1.52034729,  0.50301914, -0.91479383],\n",
       "       [ 0.44131113,  0.28108689,  0.07900984,  0.41259982,  0.0771961 ,\n",
       "         0.18367347,  0.41259982,  0.71156832,  0.7985803 ,  0.52789485,\n",
       "         1.57001676,  0.13478171, -1.25070314],\n",
       "       [ 0.29942661,  0.21934295,  0.04811133,  0.22964509,  0.10438413,\n",
       "         0.15318372,  0.22964509,  0.41753653,  0.59707724,  0.26435282,\n",
       "         1.36510707,  1.31968677,  1.29958117],\n",
       "       [ 0.27869423,  0.22520273,  0.05071627,  0.20289344,  0.05698659,\n",
       "         0.11291461,  0.20289344,  0.41460833,  0.57657022,  0.30169372,\n",
       "         1.237526  ,  1.29152639,  1.28148756],\n",
       "       [ 0.32065092,  0.25453096,  0.06478601,  0.22463768,  0.06304348,\n",
       "         0.10869565,  0.22463768,  0.45815217,  0.71521739,  0.34945652,\n",
       "         1.25977174,  1.01229965,  0.17779875],\n",
       "       [ 0.35999525,  0.24689678,  0.06095802,  0.35897436,  0.06282051,\n",
       "         0.10897436,  0.35897436,  0.51762821,  0.72525641,  0.40865385,\n",
       "         1.45807997,  0.39308099, -0.85847414],\n",
       "       [ 0.31135236,  0.22970894,  0.0527662 ,  0.23444093,  0.09493671,\n",
       "         0.15493143,  0.23444093,  0.41710619,  0.63364979,  0.26217475,\n",
       "         1.35542114,  1.23268323,  1.00687551],\n",
       "       [ 0.37083037,  0.26810441,  0.07187998,  0.33782051,  0.07435897,\n",
       "         0.125     ,  0.33782051,  0.53846154,  0.77820513,  0.41346154,\n",
       "         1.38315652,  0.49566447, -0.91196951],\n",
       "       [ 0.39231192,  0.24847662,  0.06174063,  0.35      ,  0.0725    ,\n",
       "         0.1725    ,  0.35      ,  0.579375  ,  0.75      ,  0.406875  ,\n",
       "         1.57886853,  0.34571187, -0.81938345],\n",
       "       [ 0.36338782,  0.25368727,  0.06435723,  0.29268293,  0.09085366,\n",
       "         0.14634146,  0.29268293,  0.56768293,  0.75609756,  0.42134146,\n",
       "         1.43242431,  0.61244699, -0.80199244],\n",
       "       [ 0.36096209,  0.25905395,  0.06710895,  0.30375   ,  0.0725    ,\n",
       "         0.134375  ,  0.30375   ,  0.5725    ,  0.75      ,  0.438125  ,\n",
       "         1.39338579,  0.5614904 , -0.85962649],\n",
       "       [ 0.29591008,  0.22744948,  0.05173327,  0.21321962,  0.06183369,\n",
       "         0.11727079,  0.21321962,  0.4424307 ,  0.61364606,  0.32515991,\n",
       "         1.30099257,  1.04343757,  0.56514734],\n",
       "       [ 0.29435579,  0.22379198,  0.05008285,  0.23404255,  0.08297872,\n",
       "         0.13297872,  0.23404255,  0.37367021,  0.55177305,  0.24069149,\n",
       "         1.31530985,  1.47361727,  1.83944078],\n",
       "       [ 0.31923785,  0.24605586,  0.06054348,  0.22964509,  0.0651357 ,\n",
       "         0.15970772,  0.22964509,  0.43841336,  0.73068894,  0.27870564,\n",
       "         1.29742025,  1.05813   ,  0.292921  ],\n",
       "       [ 0.38367903,  0.26514502,  0.07030188,  0.34210526,  0.05      ,\n",
       "         0.14342105,  0.34210526,  0.58174342,  0.77236842,  0.43832237,\n",
       "         1.44705349,  0.35935866, -0.92644077],\n",
       "       [ 0.36915205,  0.27809191,  0.07733511,  0.33208544,  0.06782647,\n",
       "         0.12332085,  0.33208544,  0.57212068,  0.80312706,  0.44879982,\n",
       "         1.3274462 ,  0.53277111, -0.9492017 ],\n",
       "       [ 0.29918619,  0.23276788,  0.05418089,  0.1953723 ,  0.08141962,\n",
       "         0.12526096,  0.1953723 ,  0.45929019,  0.64300626,  0.33402923,\n",
       "         1.28534137,  1.11321599,  0.49090291],\n",
       "       [ 0.3292246 ,  0.258238  ,  0.06668687,  0.24922118,  0.08099688,\n",
       "         0.12461059,  0.24922118,  0.43094496,  0.80477674,  0.30633437,\n",
       "         1.27488826,  1.10596452,  0.24919693],\n",
       "       [ 0.37150857,  0.24877698,  0.06188999,  0.33414894,  0.0612766 ,\n",
       "         0.16340426,  0.33414894,  0.54638298,  0.75319149,  0.38297872,\n",
       "         1.49333982,  0.47038878, -0.72799645],\n",
       "       [ 0.41703318,  0.28286644,  0.08001342,  0.3837963 ,  0.08055556,\n",
       "         0.15451389,  0.3837963 ,  0.63611111,  0.83333333,  0.48159722,\n",
       "         1.47431128,  0.35736225, -1.10674201],\n",
       "       [ 0.3698452 ,  0.2661116 ,  0.07081538,  0.35      ,  0.0725    ,\n",
       "         0.1       ,  0.35      ,  0.55166667,  0.75      ,  0.45166667,\n",
       "         1.38981238,  0.38643902, -0.96643884],\n",
       "       [ 0.3408553 ,  0.25358903,  0.06430739,  0.26380368,  0.10224949,\n",
       "         0.16155419,  0.26380368,  0.45219836,  0.77960123,  0.29064417,\n",
       "         1.3441248 ,  1.07862509,  0.19511318],\n",
       "       [ 0.3896195 ,  0.28614858,  0.08188101,  0.3225    ,  0.0725    ,\n",
       "         0.125     ,  0.3225    ,  0.65      ,  0.81875   ,  0.525     ,\n",
       "         1.36159859,  0.44213977, -1.12410342],\n",
       "       [ 0.29742225,  0.2326574 ,  0.05412947,  0.2173913 ,  0.06304348,\n",
       "         0.11684783,  0.2173913 ,  0.43478261,  0.60211957,  0.31793478,\n",
       "         1.27837005,  1.26623845,  1.27954035],\n",
       "       [ 0.2749017 ,  0.24119704,  0.05817601,  0.18920813,  0.04309741,\n",
       "         0.10511563,  0.18920813,  0.38354064,  0.53398739,  0.27842502,\n",
       "         1.1397391 ,  1.45547476,  1.60847596],\n",
       "       [ 0.35298131,  0.25750126,  0.0663069 ,  0.31194969,  0.07295597,\n",
       "         0.12578616,  0.31194969,  0.52830189,  0.75471698,  0.40251572,\n",
       "         1.37079446,  0.57162471, -0.77051401],\n",
       "       [ 0.34546347,  0.25655059,  0.0658182 ,  0.26576087,  0.08478261,\n",
       "         0.17173913,  0.26576087,  0.44021739,  0.77070652,  0.26847826,\n",
       "         1.34657056,  1.0661807 ,  0.27803318],\n",
       "       [ 0.303753  ,  0.23200745,  0.05382746,  0.23573417,  0.07411273,\n",
       "         0.12526096,  0.23573417,  0.42145094,  0.69415449,  0.29618998,\n",
       "         1.30923809,  1.09994499,  0.51823262],\n",
       "       [ 0.37466146,  0.25950952,  0.06734519,  0.35      ,  0.0725    ,\n",
       "         0.14791667,  0.35      ,  0.6015625 ,  0.743125  ,  0.45364583,\n",
       "         1.44372915,  0.3870163 , -0.98810147],\n",
       "       [ 0.35749941,  0.26801928,  0.07183433,  0.32628205,  0.02564103,\n",
       "         0.11538462,  0.32628205,  0.54551282,  0.74358974,  0.43012821,\n",
       "         1.33385708,  0.45756907, -0.7438749 ],\n",
       "       [ 0.33662006,  0.26324049,  0.06929555,  0.23044693,  0.07122905,\n",
       "         0.15502793,  0.23044693,  0.46573848,  0.74371508,  0.31071054,\n",
       "         1.2787549 ,  0.97307804, -0.09512984]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = np.array([list(calculate_features(x).values()) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "F1-score [1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train3, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test3)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "F1-score [1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "F1-score [1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.classification import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "F1-score [1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(metric='dtw_sakoechiba')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, Activation, Conv1D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  144\n",
      "N. LABELS:  2\n"
     ]
    }
   ],
   "source": [
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_simple_cnn(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 137, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 137, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 137, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 137, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 133, 32)           2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 133, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 133, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 133, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 131, 64)           6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 131, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 131, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 131, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 9,522\n",
      "Trainable params: 9,298\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 14 samples\n",
      "Epoch 1/5\n",
      "15/56 [=======>......................] - ETA: 0s - loss: 0.7017 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 12ms/step - loss: 0.7166 - accuracy: 0.4821 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.6727 - accuracy: 0.6429 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.6709 - accuracy: 0.6429 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.6459 - accuracy: 0.6964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.6014 - accuracy: 0.7143 - val_loss: 0.6930 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5\n",
      "F1-score [0.         0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.50      1.00      0.67        15\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.25      0.50      0.33        30\n",
      "weighted avg       0.25      0.50      0.33        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6930641531944275, 0.5]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(n_timesteps, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = build_lstm(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 280,770\n",
      "Trainable params: 280,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      "15/56 [=======>......................] - ETA: 0s - loss: 0.6035 - accuracy: 0.7333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 12ms/step - loss: 0.5917 - accuracy: 0.7679 - val_loss: 0.6928 - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.5703 - accuracy: 0.7679 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.5110 - accuracy: 0.8393 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.4695 - accuracy: 0.9107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.3945 - accuracy: 0.9464 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.3825 - accuracy: 0.9286 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.3613 - accuracy: 0.9464 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.3845 - accuracy: 0.8750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.3804 - accuracy: 0.8929 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.3871 - accuracy: 0.8750 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history_lstm = cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                       validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5\n",
      "F1-score [0.         0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.50      1.00      0.67        15\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.25      0.50      0.33        30\n",
      "weighted avg       0.25      0.50      0.33        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6923876404762268, 0.5]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_basic_motions\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'day_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-01f9fbf9c10d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mts_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mday_split\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Temperature'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Humidity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CO2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Light'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'HumidityRatio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mts_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'day_split' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "ts_list = []\n",
    "for temp in day_split:\n",
    "    ts = temp[['Temperature','Humidity','CO2','Light','HumidityRatio']].copy()\n",
    "    ts_list.append(ts)\n",
    "\n",
    "ts_array = []\n",
    "ts_size = len(day_split[1])\n",
    "for ts in ts_list:\n",
    "    ts_array.append(np.array(ts))\n",
    "    \n",
    "X = np.array(ts_array)\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_train)), X_train.shape[2] \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)\n",
    "print(\"N. FEATURES: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPool2D, Flatten, Dropout, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm2(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, n_features), return_sequences=True, \n",
    "                        kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #1\n",
    "    for _ in range(2):\n",
    "        model.add(LSTM(4, kernel_initializer='TruncatedNormal', return_sequences=True))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.04))   \n",
    "\n",
    "    #2\n",
    "    model.add(LSTM(32, kernel_initializer='TruncatedNormal', return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "    \n",
    "    #3\n",
    "    for _ in range(2):\n",
    "        model.add(Dense(256, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))\n",
    "    #4\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(64, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.7))\n",
    "\n",
    "    #5\n",
    "    model.add(Dense(32, kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = build_lstm2(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_lstm2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm2 = lstm2.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(lstm2.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn2 = X_train_cnn.reshape(X_train_cnn.shape[0], X_train_cnn.shape[1], X_train_cnn.shape[2], 1)\n",
    "X_val_cnn2 = X_val_cnn.reshape(X_val_cnn.shape[0], X_val_cnn.shape[1], X_val_cnn.shape[2], 1)\n",
    "X_test_cnn2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "X_train_cnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn2(n_timesteps, n_features, n_outputs):\n",
    "    input_shape = (n_timesteps, n_features, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ks1_first = 3\n",
    "    ks1_second = 3\n",
    "    \n",
    "    ks2_first = 4\n",
    "    ks2_second = 4\n",
    "    \n",
    "    model.add(Conv2D(filters=(3), \n",
    "                     kernel_size=(ks1_first, ks1_second),\n",
    "                     input_shape=input_shape, \n",
    "                     padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    for _ in range(2):\n",
    "        model.add(Conv2D(filters=(4), \n",
    "                     kernel_size= (ks2_first, ks2_second), \n",
    "                         padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))  \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(4):\n",
    "        model.add(Dense(64 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "    for _ in range(3):\n",
    "        model.add(Dense(128 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(1024 , kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = build_cnn2(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn2 = cnn2.fit(X_train_cnn2, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn2, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(cnn2.predict(X_test_cnn2), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn3(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = build_cnn3(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn3 = cnn3.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(cnn3.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pyts.readthedocs.io/en/stable/generated/pyts.multivariate.classification.MultivariateClassifier.html#pyts.multivariate.classification.MultivariateClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
