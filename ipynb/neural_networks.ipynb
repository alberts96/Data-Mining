{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** [Riccardo Guidotti](http://kdd.isti.cnr.it/people/riccardo-guidotti)  \n",
    "**Python version:**  3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'../data/training.csv')\n",
    "\n",
    "df['date'] =  pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "df['Time']= df['date'].apply(lambda x:x.time())\n",
    "df['Date']= df['date'].apply(lambda x:x.date())\n",
    "df['Time'] =  pd.to_timedelta(str(x) for x in df['Time'])\n",
    "df['Date'] =  pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "df['Holiday'] = df['Date'].apply(lambda x: 0 if x.weekday()<5 else 1 )\n",
    "df['Hour']= df['Time'].apply(lambda x:'hour:'+str(x)[7:9])\n",
    "\n",
    "#df.drop('HumidityRatio',inplace=True,axis=1)\n",
    "df=df[df['Light']<1000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r'../data/test.csv')\n",
    "\n",
    "test['date'] =  pd.to_datetime(test['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "test['Time']= test['date'].apply(lambda x:x.time())\n",
    "test['Date']= test['date'].apply(lambda x:x.date())\n",
    "test['Time'] =  pd.to_timedelta(str(x) for x in test['Time'])\n",
    "test['Date'] =  pd.to_datetime(test['Date'], format='%Y-%m-%d')\n",
    "test.drop('date', axis=1, inplace=True)\n",
    "test['Holiday'] = test['Date'].apply(lambda x: 0 if x.weekday()<5 else 1 )\n",
    "test['Hour']= test['Time'].apply(lambda x:'hour:'+str(x)[7:9])\n",
    "\n",
    "#test.drop('HumidityRatio',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Temperature','CO2','Light','Humidity','HumidityRatio','Holiday'] \n",
    "\n",
    "X =df[attributes].values\n",
    "y=df['Occupancy']\n",
    "X_test=test[attributes].values\n",
    "y_test=test['Occupancy']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=100, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9909208819714657\n",
      "F1-score [0.99407031 0.98063624]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4747\n",
      "           1       0.96      1.00      0.98      1421\n",
      "\n",
      "    accuracy                           0.99      6168\n",
      "   macro avg       0.98      0.99      0.99      6168\n",
      "weighted avg       0.99      0.99      0.99      6168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "hidden_layer_sizes tuple, length = n_layers - 2, default=(100,)\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "activation {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
    "Activation function for the hidden layer.\n",
    "* 'identity', no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* 'logistic', the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "* 'tanh', the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "* 'relu', the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "solver {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
    "The solver for weight optimization.\n",
    "* 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
    "* 'sgd' refers to stochastic gradient descent.\n",
    "* 'adam' refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "The default solver 'adam' works pretty well on relatively large datasets (>= 1000 training samples) in terms of both training time and validation score. For small datasets, 'lbfgs' can converge faster and perform better.\n",
    "\n",
    "alpha float, default=0.0001\n",
    "L2 penalty (regularization term) parameter.\n",
    "\n",
    "batch_size int, default='auto'\n",
    "Size of minibatches for stochastic optimizers. If the solver is 'lbfgs', the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples)\n",
    "\n",
    "learning_rate {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
    "Learning rate schedule for weight updates.\n",
    "*'constant' is a constant learning rate given by 'learning_rate_init'.\n",
    "*'invscaling' gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of *'power_t'. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "*'adaptive' keeps the learning rate constant to 'learning_rate_init' as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if 'early_stopping' is on, the current learning rate is divided by 5.\n",
    "Only used when solver='sgd'.\n",
    "\n",
    "learning_rate_init double, default=0.001\n",
    "The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "power_t double, default=0.5\n",
    "The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to 'invscaling'. Only used when solver='sgd'.\n",
    "\n",
    "max_iter int, default=200\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by 'tol') or this number of iterations. For stochastic solvers ('sgd', 'adam'), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "shuffle bool, default=True\n",
    "Whether to shuffle samples in each iteration. Only used when solver='sgd' or 'adam'.\n",
    "\n",
    "random_state int, RandomState instance or None, default=None\n",
    "If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
    "\n",
    "tol float, default=1e-4\n",
    "Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to 'adaptive', convergence is considered to be reached and training stops.\n",
    "\n",
    "verbose bool, default=False\n",
    "Whether to print progress messages to stdout.\n",
    "\n",
    "warm_start bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.\n",
    "\n",
    "momentum float, default=0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver='sgd'.\n",
    "\n",
    "early_stopping bool, default=False\n",
    "Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "validation_fraction float, default=0.1\n",
    "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True\n",
    "\n",
    "beta_1 float, default=0.9\n",
    "Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "beta_2 float, default=0.999\n",
    "Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver='adam'\n",
    "\n",
    "epsilon float, default=1e-8\n",
    "Value for numerical stability in adam. Only used when solver='adam'\n",
    "\n",
    "n_iter_no_change int, default=10\n",
    "Maximum number of epochs to not meet tol improvement. Only effective when solver='sgd' or 'adam'\n",
    "\n",
    "\n",
    "### Attributes\n",
    "loss_ float\n",
    "The current loss computed with the loss function.\n",
    "\n",
    "coefs_ list, length n_layers - 1\n",
    "The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "\n",
    "intercepts_ list, length n_layers - 1\n",
    "The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "\n",
    "n_iter_ int,\n",
    "The number of iterations the solver has ran.\n",
    "\n",
    "n_layers_ int\n",
    "Number of layers.\n",
    "\n",
    "n_outputs_ int\n",
    "Number of outputs.\n",
    "\n",
    "out_activation_ string\n",
    "Name of the output activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different learning rate schedules and momentum parameters\n",
    "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'adam', 'learning_rate_init': 0.01}]\n",
    "\n",
    "labels = [\"constant learning-rate\", \"constant with momentum\",\n",
    "           \"inv-scaling with nesterovs momentum\", \"adam\"]\n",
    "\n",
    "plot_args = [{'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'green', 'linestyle': '-'},\n",
    "             {'c': 'blue', 'linestyle': '--'},\n",
    "             {'c': 'black', 'linestyle': '-.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: constant learning-rate\n",
      "Training set score: 0.767241\n",
      "Training set loss: 0.661294\n",
      "training: constant with momentum\n",
      "Training set score: 0.767241\n",
      "Training set loss: 12.124717\n",
      "training: inv-scaling with nesterovs momentum\n",
      "Training set score: 0.767241\n",
      "Training set loss: 41.811081\n",
      "training: adam\n",
      "Training set score: 0.990823\n",
      "Training set loss: 0.046600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "        \n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(15, 10))      \n",
    "  \n",
    "for label, param, args in zip(labels, params,plot_args):\n",
    "    print(\"training: %s\" % label)\n",
    "    mlp = MLPClassifier(random_state=0,\n",
    "                           max_iter=200, **param)\n",
    "\n",
    "        # some parameter combinations will not converge as can be seen on the\n",
    "        # plots so they are ignored here\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                                    module=\"sklearn\")\n",
    "        mlp.fit(X, y)\n",
    "\n",
    "    axes.plot(mlp.loss_curve_, label=label, **args)\n",
    "    print(\"Training set score: %f\" % mlp.score(X, y))\n",
    "    print(\"Training set loss: %f\" % mlp.loss_)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "axes.set_ylabel(\"Loss\")\n",
    "axes.set_xlabel(\"Iterations\")\n",
    "axes.set_xlim(0,85)\n",
    "axes.set_ylim(0.025,0.55)\n",
    "fig.legend(axes.get_lines(), labels,  loc=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021912353240478785\n",
      "Accuracy 0.9917315175097277\n",
      "F1-score [0.99460717 0.98228552]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4747\n",
      "           1       0.97      1.00      0.98      1421\n",
      "\n",
      "    accuracy                           0.99      6168\n",
      "   macro avg       0.98      0.99      0.99      6168\n",
      "weighted avg       0.99      0.99      0.99      6168\n",
      "\n",
      "0.02567476721116297\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf=None\n",
    "#layer size = 2/3 inputSize + outputSzie\n",
    "clf = MLPClassifier(random_state=0,solver= 'adam', learning_rate_init= 0.01, hidden_layer_sizes=(64,32,16))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.predict_log_proba(X_test)\n",
    "print(clf.loss_)\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "plt.plot(clf.loss_curve_, label=\"Train\")\n",
    "clf.fit(X_val, y_val)\n",
    "print(clf.loss_)\n",
    "plt.plot(clf.loss_curve_, label=\"Val\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0,solver= 'adam', learning_rate_init= 0.01, hidden_layer_sizes=(35,21,7))\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=20)\n",
    "print('Accuracy: %0.4f (+/- %0.3f)' % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=20, scoring='f1_macro')\n",
    "print('F1-score: %0.4f (+/- %0.3f)' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=0,solver= 'sgd', learning_rate= 'constant', momentum= .9, hidden_layer_sizes=(35,21,7),\n",
    "           nesterovs_momentum= True, learning_rate_init= 0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.predict_log_proba(X_test)\n",
    "print(clf.loss_)\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "plt.plot(clf.loss_curve_, label=\"Train\")\n",
    "clf.fit(X_val, y_val)\n",
    "print(clf.loss_)\n",
    "plt.plot(clf.loss_curve_, label=\"Val\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lift_curve(y_test, y_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041360055851465974\n",
      "Accuracy 0.9907587548638133\n",
      "F1-score [0.99396378 0.98029727]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4747\n",
      "           1       0.96      1.00      0.98      1421\n",
      "\n",
      "    accuracy                           0.99      6168\n",
      "   macro avg       0.98      0.99      0.99      6168\n",
      "weighted avg       0.99      0.99      0.99      6168\n",
      "\n",
      "0.04790895610832743\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(128, 64, 32,), alpha=0.1, learning_rate='adaptive', \n",
    "                    activation='tanh', early_stopping=False, momentum=0.9, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.predict_log_proba(X_test)\n",
    "print(clf.loss_)\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "plt.plot(clf.loss_curve_, label=\"Train\")\n",
    "clf.fit(X_val, y_val)\n",
    "print(clf.loss_)\n",
    "plt.plot(clf.loss_curve_, label=\"Val\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04020681094366478\n",
      "Accuracy 0.9907587548638133\n",
      "F1-score [0.99396506 0.98028364]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4747\n",
      "           1       0.96      1.00      0.98      1421\n",
      "\n",
      "    accuracy                           0.99      6168\n",
      "   macro avg       0.98      0.99      0.99      6168\n",
      "weighted avg       0.99      0.99      0.99      6168\n",
      "\n",
      "0.06732499385135472\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver= 'sgd', learning_rate= 'invscaling', momentum= 0,\n",
    "            learning_rate_init= 0.8)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.predict_log_proba(X_test)\n",
    "print(clf.loss_)\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "plt.plot(clf.loss_curve_, label=\"Train\")\n",
    "clf.fit(X_val, y_val)\n",
    "print(clf.loss_)\n",
    "plt.plot(clf.loss_curve_, label=\"Val\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>one <b>epoch</b> = one forward pass and one backward pass of all the training examples\n",
    "<li><b>batch size</b> = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "<li>number of <b>iterations</b> = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).\n",
    "</ul><br>\n",
    "Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chose a batch size : <ul>\n",
    "<li><b>batch</b> mode: where the batch size is equal to the total dataset thus making the iteration and epoch values equivalent\n",
    "<li><b>mini-batch</b> mode: where the batch size is greater than one but less than the total dataset size. Usually, a number that can be divided into the total dataset size.\n",
    "<il><b>stochastic</b> mode: where the batch size is equal to one. Therefore the gradient and the neural network parameters are updated after each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    n_feature = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(35, input_dim=n_feature, activation='relu'))\n",
    "    model.add(Dense(21, activation='relu'))\n",
    "    model.add(Dense(7, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7b29a6d6594b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                     **self._function_kwargs)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   1452\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m                 \u001b[0m_raise_invalid_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   1419\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m                                         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m   1422\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_metric'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m         self._metrics_function = theano.function(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1837\u001b[0m                   \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m                   \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m                   name=name)\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchange_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_test_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys, name)\u001b[0m\n\u001b[0;32m   1517\u001b[0m                         optimizer, inputs, outputs)\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1519\u001b[1;33m                     \u001b[0moptimizer_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    249\u001b[0m                     \u001b[0mnb_nodes_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                     \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m                     \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph, start_from)\u001b[0m\n\u001b[0;32m   2520\u001b[0m                         \u001b[0mchanged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m                         \u001b[0mnode_created\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlopt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mchange_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_imported\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m                         \u001b[0mchanged\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mapply_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_cleanup_sub_profs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2523\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mglobal_process_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlopt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_use\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2524\u001b[0m                             \u001b[0mmax_use_abort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mapply_cleanup\u001b[1;34m(profs_dict)\u001b[0m\n\u001b[0;32m   2433\u001b[0m                 \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_imported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2434\u001b[0m                 \u001b[0mt_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2435\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2436\u001b[0m                 \u001b[0mtime_opts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcopt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_opt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2437\u001b[0m                 \u001b[0mprofs_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcopt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    901\u001b[0m                         \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MergeOptimizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                         \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_all_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MergeOptimizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mInconsistencyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m                     \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\toolbox.py\u001b[0m in \u001b[0;36mreplace_all_validate\u001b[1;34m(self, fgraph, replacements, reason, verbose)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrevert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\toolbox.py\u001b[0m in \u001b[0;36mvalidate_\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mcf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\fg.py\u001b[0m in \u001b[0;36mexecute_callbacks\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mtf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_callbacks_times\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_callbacks_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, epochs=50, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11507/11507 [==============================] - 7s 594us/step - loss: 0.1692 - accuracy: 0.9339\n",
      "Epoch 2/50\n",
      "11507/11507 [==============================] - 6s 564us/step - loss: 0.0350 - accuracy: 0.9919\n",
      "Epoch 3/50\n",
      "11507/11507 [==============================] - 7s 599us/step - loss: 0.0339 - accuracy: 0.9917\n",
      "Epoch 4/50\n",
      "11507/11507 [==============================] - 2s 195us/step - loss: 0.0333 - accuracy: 0.99170s - loss: 0.0341 - accu\n",
      "Epoch 5/50\n",
      "11507/11507 [==============================] - 3s 279us/step - loss: 0.0324 - accuracy: 0.99200s - loss: 0.0317 - ac\n",
      "Epoch 6/50\n",
      "11507/11507 [==============================] - 4s 330us/step - loss: 0.0316 - accuracy: 0.9918\n",
      "Epoch 7/50\n",
      "11507/11507 [==============================] - 2s 176us/step - loss: 0.0313 - accuracy: 0.9919 - ETA: 0s -\n",
      "Epoch 8/50\n",
      "11507/11507 [==============================] - 5s 419us/step - loss: 0.0311 - accuracy: 0.9917\n",
      "Epoch 9/50\n",
      "11507/11507 [==============================] - 4s 372us/step - loss: 0.0303 - accuracy: 0.9919\n",
      "Epoch 10/50\n",
      "11507/11507 [==============================] - 2s 169us/step - loss: 0.0303 - accuracy: 0.9919\n",
      "Epoch 11/50\n",
      "11507/11507 [==============================] - 1s 122us/step - loss: 0.0300 - accuracy: 0.9919\n",
      "Epoch 12/50\n",
      "11507/11507 [==============================] - 2s 184us/step - loss: 0.0293 - accuracy: 0.9918\n",
      "Epoch 13/50\n",
      "11507/11507 [==============================] - 2s 150us/step - loss: 0.0296 - accuracy: 0.9920\n",
      "Epoch 14/50\n",
      "11507/11507 [==============================] - 3s 263us/step - loss: 0.0293 - accuracy: 0.99210s - loss: 0.0279 \n",
      "Epoch 15/50\n",
      "11507/11507 [==============================] - 3s 231us/step - loss: 0.0287 - accuracy: 0.9919\n",
      "Epoch 16/50\n",
      "11507/11507 [==============================] - 2s 187us/step - loss: 0.0289 - accuracy: 0.9921\n",
      "Epoch 17/50\n",
      "11507/11507 [==============================] - 2s 208us/step - loss: 0.0285 - accuracy: 0.9920\n",
      "Epoch 18/50\n",
      "11507/11507 [==============================] - 4s 308us/step - loss: 0.0281 - accuracy: 0.9920\n",
      "Epoch 19/50\n",
      "11507/11507 [==============================] - 7s 609us/step - loss: 0.0280 - accuracy: 0.9922\n",
      "Epoch 20/50\n",
      "11507/11507 [==============================] - 8s 652us/step - loss: 0.0278 - accuracy: 0.9920\n",
      "Epoch 21/50\n",
      "11507/11507 [==============================] - 3s 268us/step - loss: 0.0277 - accuracy: 0.9920\n",
      "Epoch 22/50\n",
      "11507/11507 [==============================] - 2s 134us/step - loss: 0.0273 - accuracy: 0.9922\n",
      "Epoch 23/50\n",
      "11507/11507 [==============================] - 5s 477us/step - loss: 0.0276 - accuracy: 0.9923\n",
      "Epoch 24/50\n",
      "11507/11507 [==============================] - 9s 801us/step - loss: 0.0267 - accuracy: 0.9926\n",
      "Epoch 25/50\n",
      "11507/11507 [==============================] - 8s 737us/step - loss: 0.0269 - accuracy: 0.9921\n",
      "Epoch 26/50\n",
      "11507/11507 [==============================] - 2s 159us/step - loss: 0.0268 - accuracy: 0.9917\n",
      "Epoch 27/50\n",
      "11507/11507 [==============================] - 2s 132us/step - loss: 0.0267 - accuracy: 0.9921\n",
      "Epoch 28/50\n",
      "11507/11507 [==============================] - 2s 185us/step - loss: 0.0266 - accuracy: 0.9917\n",
      "Epoch 29/50\n",
      "11507/11507 [==============================] - 2s 192us/step - loss: 0.0260 - accuracy: 0.9920\n",
      "Epoch 30/50\n",
      "11507/11507 [==============================] - 2s 161us/step - loss: 0.0259 - accuracy: 0.9922\n",
      "Epoch 31/50\n",
      "11507/11507 [==============================] - 2s 170us/step - loss: 0.0261 - accuracy: 0.9921\n",
      "Epoch 32/50\n",
      "11507/11507 [==============================] - 2s 176us/step - loss: 0.0257 - accuracy: 0.99220s - l\n",
      "Epoch 33/50\n",
      "11507/11507 [==============================] - 2s 152us/step - loss: 0.0260 - accuracy: 0.9927\n",
      "Epoch 34/50\n",
      "11507/11507 [==============================] - 2s 168us/step - loss: 0.0257 - accuracy: 0.9920\n",
      "Epoch 35/50\n",
      "11507/11507 [==============================] - 1s 128us/step - loss: 0.0257 - accuracy: 0.9923\n",
      "Epoch 36/50\n",
      "11507/11507 [==============================] - 2s 147us/step - loss: 0.0253 - accuracy: 0.9925\n",
      "Epoch 37/50\n",
      "11507/11507 [==============================] - 3s 302us/step - loss: 0.0255 - accuracy: 0.9921\n",
      "Epoch 38/50\n",
      "11507/11507 [==============================] - 2s 166us/step - loss: 0.0251 - accuracy: 0.9921\n",
      "Epoch 39/50\n",
      "11507/11507 [==============================] - 2s 188us/step - loss: 0.0255 - accuracy: 0.9923\n",
      "Epoch 40/50\n",
      "11507/11507 [==============================] - 2s 173us/step - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 41/50\n",
      "11507/11507 [==============================] - 2s 167us/step - loss: 0.0253 - accuracy: 0.9926\n",
      "Epoch 42/50\n",
      "11507/11507 [==============================] - 2s 165us/step - loss: 0.0250 - accuracy: 0.9924\n",
      "Epoch 43/50\n",
      "11507/11507 [==============================] - 2s 148us/step - loss: 0.0253 - accuracy: 0.9926\n",
      "Epoch 44/50\n",
      "11507/11507 [==============================] - 1s 120us/step - loss: 0.0244 - accuracy: 0.9927\n",
      "Epoch 45/50\n",
      "11507/11507 [==============================] - 1s 127us/step - loss: 0.0243 - accuracy: 0.9929\n",
      "Epoch 46/50\n",
      "11507/11507 [==============================] - 1s 126us/step - loss: 0.0245 - accuracy: 0.9925\n",
      "Epoch 47/50\n",
      "11507/11507 [==============================] - 3s 254us/step - loss: 0.0245 - accuracy: 0.9927\n",
      "Epoch 48/50\n",
      "11507/11507 [==============================] - 2s 133us/step - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 49/50\n",
      "11507/11507 [==============================] - 2s 139us/step - loss: 0.0245 - accuracy: 0.9927\n",
      "Epoch 50/50\n",
      "11507/11507 [==============================] - 2s 142us/step - loss: 0.0245 - accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model()\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, epochs=50, batch_size=50).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1['loss'], label='Loss 10')\n",
    "plt.plot(history2['loss'], label='Loss 50')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6168/6168 [==============================] - 0s 26us/step\n",
      "6168/6168 [==============================] - 0s 30us/step\n",
      "Loss 0.025931, Accuracy 0.991732\n",
      "Loss 0.027803, Accuracy 0.990759\n"
     ]
    }
   ],
   "source": [
    "test_loss_1, test_acc_1 = model1.evaluate(X_test, y_test)\n",
    "test_loss_2, test_acc_2 = model2.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7696173800259404\n",
      "F1-score [0.86981219 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      4747\n",
      "           1       0.00      0.00      0.00      1421\n",
      "\n",
      "    accuracy                           0.77      6168\n",
      "   macro avg       0.38      0.50      0.43      6168\n",
      "weighted avg       0.59      0.77      0.67      6168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test).astype(int)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "#Build your model here\n",
    "ann_viz(model1,view=True, filename=\"net.gv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "from keras.utils import plot_model\n",
    "plot_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3187479b71cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11512 samples, validate on 2879 samples\n",
      "Epoch 1/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.1726 - accuracy: 0.9580 - val_loss: 0.0546 - val_accuracy: 0.9882\n",
      "Epoch 2/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0401 - accuracy: 0.9911 - val_loss: 0.0480 - val_accuracy: 0.9882\n",
      "Epoch 3/1000\n",
      "11512/11512 [==============================] - 4s 367us/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.0467 - val_accuracy: 0.9882\n",
      "Epoch 4/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0362 - accuracy: 0.9913 - val_loss: 0.0481 - val_accuracy: 0.9882\n",
      "Epoch 5/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0361 - accuracy: 0.9914 - val_loss: 0.0470 - val_accuracy: 0.9882\n",
      "Epoch 6/1000\n",
      "11512/11512 [==============================] - 4s 329us/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.0476 - val_accuracy: 0.9882\n",
      "Epoch 7/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0467 - val_accuracy: 0.9878\n",
      "Epoch 8/1000\n",
      "11512/11512 [==============================] - 4s 327us/step - loss: 0.0356 - accuracy: 0.9916 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 9/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.0455 - val_accuracy: 0.9878\n",
      "Epoch 10/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0352 - accuracy: 0.9912 - val_loss: 0.0453 - val_accuracy: 0.9885\n",
      "Epoch 11/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0460 - val_accuracy: 0.9875\n",
      "Epoch 12/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.0474 - val_accuracy: 0.9882\n",
      "Epoch 13/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 0.0454 - val_accuracy: 0.9882\n",
      "Epoch 14/1000\n",
      "11512/11512 [==============================] - 4s 346us/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 15/1000\n",
      "11512/11512 [==============================] - 4s 327us/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 0.0465 - val_accuracy: 0.9882\n",
      "Epoch 16/1000\n",
      "11512/11512 [==============================] - 4s 360us/step - loss: 0.0349 - accuracy: 0.9913 - val_loss: 0.0449 - val_accuracy: 0.9882\n",
      "Epoch 17/1000\n",
      "11512/11512 [==============================] - 4s 358us/step - loss: 0.0348 - accuracy: 0.9914 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
      "Epoch 18/1000\n",
      "11512/11512 [==============================] - 4s 329us/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0466 - val_accuracy: 0.9882\n",
      "Epoch 19/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0347 - accuracy: 0.9914 - val_loss: 0.0455 - val_accuracy: 0.9878\n",
      "Epoch 20/1000\n",
      "11512/11512 [==============================] - 4s 329us/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0451 - val_accuracy: 0.9882\n",
      "Epoch 21/1000\n",
      "11512/11512 [==============================] - 4s 368us/step - loss: 0.0343 - accuracy: 0.9913 - val_loss: 0.0459 - val_accuracy: 0.9885\n",
      "Epoch 22/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0348 - accuracy: 0.9911 - val_loss: 0.0451 - val_accuracy: 0.9882\n",
      "Epoch 23/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0345 - accuracy: 0.9915 - val_loss: 0.0450 - val_accuracy: 0.9882\n",
      "Epoch 24/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0345 - accuracy: 0.9915 - val_loss: 0.0447 - val_accuracy: 0.9882\n",
      "Epoch 25/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0346 - accuracy: 0.9915 - val_loss: 0.0444 - val_accuracy: 0.9882\n",
      "Epoch 26/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0344 - accuracy: 0.9916 - val_loss: 0.0457 - val_accuracy: 0.9885\n",
      "Epoch 27/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0344 - accuracy: 0.9916 - val_loss: 0.0446 - val_accuracy: 0.9878\n",
      "Epoch 28/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0343 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9885\n",
      "Epoch 29/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0344 - accuracy: 0.9914 - val_loss: 0.0454 - val_accuracy: 0.9882\n",
      "Epoch 30/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 0.0470 - val_accuracy: 0.9885\n",
      "Epoch 31/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.0449 - val_accuracy: 0.9885\n",
      "Epoch 32/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0344 - accuracy: 0.9914 - val_loss: 0.0454 - val_accuracy: 0.9878\n",
      "Epoch 33/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.0451 - val_accuracy: 0.9878\n",
      "Epoch 34/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0341 - accuracy: 0.9915 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 35/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 0.0439 - val_accuracy: 0.9878\n",
      "Epoch 36/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
      "Epoch 37/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.0447 - val_accuracy: 0.9885\n",
      "Epoch 38/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.0461 - val_accuracy: 0.9878\n",
      "Epoch 39/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0343 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9885\n",
      "Epoch 40/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0341 - accuracy: 0.9914 - val_loss: 0.0448 - val_accuracy: 0.9875\n",
      "Epoch 41/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 0.0439 - val_accuracy: 0.9882\n",
      "Epoch 42/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0342 - accuracy: 0.9917 - val_loss: 0.0444 - val_accuracy: 0.9885\n",
      "Epoch 43/1000\n",
      "11512/11512 [==============================] - 3s 272us/step - loss: 0.0341 - accuracy: 0.9917 - val_loss: 0.0443 - val_accuracy: 0.9878\n",
      "Epoch 44/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0341 - accuracy: 0.9917 - val_loss: 0.0443 - val_accuracy: 0.9885\n",
      "Epoch 45/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
      "Epoch 46/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 47/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0339 - accuracy: 0.9914 - val_loss: 0.0450 - val_accuracy: 0.9882\n",
      "Epoch 48/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0342 - accuracy: 0.9915 - val_loss: 0.0444 - val_accuracy: 0.9878\n",
      "Epoch 49/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0340 - accuracy: 0.9914 - val_loss: 0.0455 - val_accuracy: 0.9885\n",
      "Epoch 50/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.0459 - val_accuracy: 0.9885\n",
      "Epoch 51/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0341 - accuracy: 0.9915 - val_loss: 0.0448 - val_accuracy: 0.9878\n",
      "Epoch 52/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 0.0445 - val_accuracy: 0.9885\n",
      "Epoch 53/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9885\n",
      "Epoch 54/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0341 - accuracy: 0.9915 - val_loss: 0.0450 - val_accuracy: 0.9885\n",
      "Epoch 55/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.0461 - val_accuracy: 0.9882\n",
      "Epoch 56/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0338 - accuracy: 0.9913 - val_loss: 0.0453 - val_accuracy: 0.9875\n",
      "Epoch 57/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 0.0449 - val_accuracy: 0.9885\n",
      "Epoch 58/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0341 - accuracy: 0.9914 - val_loss: 0.0445 - val_accuracy: 0.9885\n",
      "Epoch 59/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0337 - accuracy: 0.9916 - val_loss: 0.0463 - val_accuracy: 0.9882\n",
      "Epoch 60/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0337 - accuracy: 0.9914 - val_loss: 0.0445 - val_accuracy: 0.9885\n",
      "Epoch 61/1000\n",
      "11512/11512 [==============================] - 4s 333us/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0447 - val_accuracy: 0.9878\n",
      "Epoch 62/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0340 - accuracy: 0.9916 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
      "Epoch 63/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0338 - accuracy: 0.9916 - val_loss: 0.0448 - val_accuracy: 0.9885\n",
      "Epoch 64/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0439 - val_accuracy: 0.9882\n",
      "Epoch 65/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0338 - accuracy: 0.9914 - val_loss: 0.0446 - val_accuracy: 0.9885\n",
      "Epoch 66/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
      "Epoch 67/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0339 - accuracy: 0.9914 - val_loss: 0.0439 - val_accuracy: 0.9885\n",
      "Epoch 68/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0336 - accuracy: 0.9915 - val_loss: 0.0450 - val_accuracy: 0.9885\n",
      "Epoch 69/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0339 - accuracy: 0.9913 - val_loss: 0.0453 - val_accuracy: 0.9882\n",
      "Epoch 70/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0433 - val_accuracy: 0.9885\n",
      "Epoch 71/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 72/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 0.0458 - val_accuracy: 0.9885\n",
      "Epoch 73/1000\n",
      "11512/11512 [==============================] - 4s 329us/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 0.0452 - val_accuracy: 0.9878\n",
      "Epoch 74/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.0451 - val_accuracy: 0.9875\n",
      "Epoch 75/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0336 - accuracy: 0.9915 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 76/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.0435 - val_accuracy: 0.9882\n",
      "Epoch 77/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.0441 - val_accuracy: 0.9878\n",
      "Epoch 78/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0338 - accuracy: 0.9915 - val_loss: 0.0436 - val_accuracy: 0.9882\n",
      "Epoch 79/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0337 - accuracy: 0.9914 - val_loss: 0.0450 - val_accuracy: 0.9885\n",
      "Epoch 80/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0336 - accuracy: 0.9915 - val_loss: 0.0469 - val_accuracy: 0.9885\n",
      "Epoch 81/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.0438 - val_accuracy: 0.9885\n",
      "Epoch 82/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0336 - accuracy: 0.9915 - val_loss: 0.0454 - val_accuracy: 0.9878\n",
      "Epoch 83/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.0444 - val_accuracy: 0.9878\n",
      "Epoch 84/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.0437 - val_accuracy: 0.9885\n",
      "Epoch 85/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0330 - accuracy: 0.9916 - val_loss: 0.0439 - val_accuracy: 0.9878\n",
      "Epoch 86/1000\n",
      "11512/11512 [==============================] - 4s 321us/step - loss: 0.0330 - accuracy: 0.9914 - val_loss: 0.0430 - val_accuracy: 0.9882\n",
      "Epoch 87/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.0436 - val_accuracy: 0.9885\n",
      "Epoch 88/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0328 - accuracy: 0.9915 - val_loss: 0.0446 - val_accuracy: 0.9885\n",
      "Epoch 89/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0433 - val_accuracy: 0.9882\n",
      "Epoch 90/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0328 - accuracy: 0.9914 - val_loss: 0.0422 - val_accuracy: 0.9882\n",
      "Epoch 91/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0328 - accuracy: 0.9914 - val_loss: 0.0428 - val_accuracy: 0.9882\n",
      "Epoch 92/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0330 - accuracy: 0.9916 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 93/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0436 - val_accuracy: 0.9878\n",
      "Epoch 94/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0326 - accuracy: 0.9916 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 95/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 0.0422 - val_accuracy: 0.9885\n",
      "Epoch 96/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0430 - val_accuracy: 0.9885\n",
      "Epoch 97/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 98/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0327 - accuracy: 0.9914 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
      "Epoch 99/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0424 - val_accuracy: 0.9882\n",
      "Epoch 100/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
      "Epoch 101/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.0447 - val_accuracy: 0.9885\n",
      "Epoch 102/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 103/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0324 - accuracy: 0.9916 - val_loss: 0.0426 - val_accuracy: 0.9882\n",
      "Epoch 104/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0323 - accuracy: 0.9917 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 105/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 0.0422 - val_accuracy: 0.9882\n",
      "Epoch 106/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.0423 - val_accuracy: 0.9885\n",
      "Epoch 107/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0323 - accuracy: 0.9917 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 108/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.0440 - val_accuracy: 0.9885\n",
      "Epoch 109/1000\n",
      "11512/11512 [==============================] - 4s 325us/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9882\n",
      "Epoch 110/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0320 - accuracy: 0.9917 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 111/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0317 - accuracy: 0.9917 - val_loss: 0.0458 - val_accuracy: 0.9885\n",
      "Epoch 112/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9885\n",
      "Epoch 113/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0320 - accuracy: 0.9916 - val_loss: 0.0428 - val_accuracy: 0.9885\n",
      "Epoch 114/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 115/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9885\n",
      "Epoch 116/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
      "Epoch 117/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.0436 - val_accuracy: 0.9885\n",
      "Epoch 118/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 119/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0317 - accuracy: 0.9917 - val_loss: 0.0430 - val_accuracy: 0.9885\n",
      "Epoch 120/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0314 - accuracy: 0.9917 - val_loss: 0.0428 - val_accuracy: 0.9889\n",
      "Epoch 121/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 0.0427 - val_accuracy: 0.9885\n",
      "Epoch 122/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0314 - accuracy: 0.9914 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 123/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0313 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9885\n",
      "Epoch 124/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0309 - accuracy: 0.9916 - val_loss: 0.0451 - val_accuracy: 0.9885\n",
      "Epoch 125/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
      "Epoch 126/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.0437 - val_accuracy: 0.9885\n",
      "Epoch 127/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.0452 - val_accuracy: 0.9885\n",
      "Epoch 128/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
      "Epoch 129/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 130/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
      "Epoch 131/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 132/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 0.0431 - val_accuracy: 0.9885\n",
      "Epoch 133/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.0436 - val_accuracy: 0.9885\n",
      "Epoch 134/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 0.0436 - val_accuracy: 0.9885\n",
      "Epoch 135/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 0.0431 - val_accuracy: 0.9892\n",
      "Epoch 136/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.0428 - val_accuracy: 0.9892\n",
      "Epoch 137/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.0426 - val_accuracy: 0.9892\n",
      "Epoch 138/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.0434 - val_accuracy: 0.9882\n",
      "Epoch 139/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 0.0427 - val_accuracy: 0.9892\n",
      "Epoch 140/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0439 - val_accuracy: 0.9885\n",
      "Epoch 141/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 142/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 143/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.0435 - val_accuracy: 0.9892\n",
      "Epoch 144/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0464 - val_accuracy: 0.9882\n",
      "Epoch 145/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 146/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.0444 - val_accuracy: 0.9882\n",
      "Epoch 147/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 0.0427 - val_accuracy: 0.9896\n",
      "Epoch 148/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0437 - val_accuracy: 0.9885\n",
      "Epoch 149/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0287 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9878\n",
      "Epoch 150/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 151/1000\n",
      "11512/11512 [==============================] - 4s 333us/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0437 - val_accuracy: 0.9885\n",
      "Epoch 152/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0449 - val_accuracy: 0.9878\n",
      "Epoch 153/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0436 - val_accuracy: 0.9889\n",
      "Epoch 154/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0461 - val_accuracy: 0.9882\n",
      "Epoch 155/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.0450 - val_accuracy: 0.9882\n",
      "Epoch 156/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0429 - val_accuracy: 0.9885\n",
      "Epoch 157/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.0451 - val_accuracy: 0.9885\n",
      "Epoch 158/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.0432 - val_accuracy: 0.9882\n",
      "Epoch 159/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.0435 - val_accuracy: 0.9889\n",
      "Epoch 160/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0432 - val_accuracy: 0.9896\n",
      "Epoch 161/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.0444 - val_accuracy: 0.9885\n",
      "Epoch 162/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0438 - val_accuracy: 0.9878\n",
      "Epoch 163/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0278 - accuracy: 0.9917 - val_loss: 0.0460 - val_accuracy: 0.9885\n",
      "Epoch 164/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 0.0427 - val_accuracy: 0.9896\n",
      "Epoch 165/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.0472 - val_accuracy: 0.9854\n",
      "Epoch 166/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
      "Epoch 167/1000\n",
      "11512/11512 [==============================] - 4s 328us/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0432 - val_accuracy: 0.9896\n",
      "Epoch 168/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 169/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 170/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0433 - val_accuracy: 0.9882\n",
      "Epoch 171/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0446 - val_accuracy: 0.9882\n",
      "Epoch 172/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0278 - accuracy: 0.9911 - val_loss: 0.0442 - val_accuracy: 0.9885\n",
      "Epoch 173/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0421 - val_accuracy: 0.9896\n",
      "Epoch 174/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0432 - val_accuracy: 0.9878\n",
      "Epoch 175/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0433 - val_accuracy: 0.9885\n",
      "Epoch 176/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0437 - val_accuracy: 0.9882\n",
      "Epoch 177/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0457 - val_accuracy: 0.9882\n",
      "Epoch 178/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
      "Epoch 179/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0430 - val_accuracy: 0.9896\n",
      "Epoch 180/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0454 - val_accuracy: 0.9858\n",
      "Epoch 181/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 182/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.0432 - val_accuracy: 0.9875\n",
      "Epoch 183/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0428 - val_accuracy: 0.9882\n",
      "Epoch 184/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.0448 - val_accuracy: 0.9892\n",
      "Epoch 185/1000\n",
      "11512/11512 [==============================] - 4s 331us/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0424 - val_accuracy: 0.9896\n",
      "Epoch 186/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.0441 - val_accuracy: 0.9882\n",
      "Epoch 187/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.0431 - val_accuracy: 0.9878\n",
      "Epoch 188/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0432 - val_accuracy: 0.9878\n",
      "Epoch 189/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.0466 - val_accuracy: 0.9878\n",
      "Epoch 190/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0273 - accuracy: 0.9916 - val_loss: 0.0451 - val_accuracy: 0.9882\n",
      "Epoch 191/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.0451 - val_accuracy: 0.9882\n",
      "Epoch 192/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0429 - val_accuracy: 0.9889\n",
      "Epoch 193/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0439 - val_accuracy: 0.9882\n",
      "Epoch 194/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0428 - val_accuracy: 0.9892\n",
      "Epoch 195/1000\n",
      "11512/11512 [==============================] - 4s 341us/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.0456 - val_accuracy: 0.9882\n",
      "Epoch 196/1000\n",
      "11512/11512 [==============================] - 4s 339us/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0424 - val_accuracy: 0.9896\n",
      "Epoch 197/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0434 - val_accuracy: 0.9882\n",
      "Epoch 198/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0433 - val_accuracy: 0.9871\n",
      "Epoch 199/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0435 - val_accuracy: 0.9896\n",
      "Epoch 200/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0423 - val_accuracy: 0.9896\n",
      "Epoch 201/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0431 - val_accuracy: 0.9889\n",
      "Epoch 202/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0463 - val_accuracy: 0.9840\n",
      "Epoch 203/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0472 - val_accuracy: 0.9868\n",
      "Epoch 204/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0485 - val_accuracy: 0.9878\n",
      "Epoch 205/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0269 - accuracy: 0.9910 - val_loss: 0.0447 - val_accuracy: 0.9885\n",
      "Epoch 206/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.0432 - val_accuracy: 0.9871\n",
      "Epoch 207/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 208/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0445 - val_accuracy: 0.9882\n",
      "Epoch 209/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.0432 - val_accuracy: 0.9871\n",
      "Epoch 210/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
      "Epoch 211/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.0470 - val_accuracy: 0.9865\n",
      "Epoch 212/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0434 - val_accuracy: 0.9871\n",
      "Epoch 213/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.0427 - val_accuracy: 0.9871\n",
      "Epoch 214/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.0446 - val_accuracy: 0.9882\n",
      "Epoch 215/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.0454 - val_accuracy: 0.9878\n",
      "Epoch 216/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0489 - val_accuracy: 0.9882\n",
      "Epoch 217/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9875\n",
      "Epoch 218/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0426 - val_accuracy: 0.9871\n",
      "Epoch 219/1000\n",
      "11512/11512 [==============================] - 4s 327us/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0426 - val_accuracy: 0.9889\n",
      "Epoch 220/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 221/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.0440 - val_accuracy: 0.9875\n",
      "Epoch 222/1000\n",
      "11512/11512 [==============================] - 3s 267us/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 0.0453 - val_accuracy: 0.9851\n",
      "Epoch 223/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0265 - accuracy: 0.9908 - val_loss: 0.0462 - val_accuracy: 0.9882\n",
      "Epoch 224/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.0439 - val_accuracy: 0.9868\n",
      "Epoch 225/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0437 - val_accuracy: 0.9865\n",
      "Epoch 226/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0435 - val_accuracy: 0.9871\n",
      "Epoch 227/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0427 - val_accuracy: 0.9878\n",
      "Epoch 228/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0449 - val_accuracy: 0.9875\n",
      "Epoch 229/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0425 - val_accuracy: 0.9875\n",
      "Epoch 230/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 0.0457 - val_accuracy: 0.9882\n",
      "Epoch 231/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0261 - accuracy: 0.9914 - val_loss: 0.0455 - val_accuracy: 0.9878\n",
      "Epoch 232/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0447 - val_accuracy: 0.9868\n",
      "Epoch 233/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
      "Epoch 234/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0477 - val_accuracy: 0.9858\n",
      "Epoch 235/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 0.0434 - val_accuracy: 0.9875\n",
      "Epoch 236/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.0464 - val_accuracy: 0.9882\n",
      "Epoch 237/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.0431 - val_accuracy: 0.9878\n",
      "Epoch 238/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.0474 - val_accuracy: 0.9861\n",
      "Epoch 239/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0447 - val_accuracy: 0.9871\n",
      "Epoch 240/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0460 - val_accuracy: 0.9882\n",
      "Epoch 241/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.0448 - val_accuracy: 0.9875\n",
      "Epoch 242/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
      "Epoch 243/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0444 - val_accuracy: 0.9868\n",
      "Epoch 244/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0456 - val_accuracy: 0.9861\n",
      "Epoch 245/1000\n",
      "11512/11512 [==============================] - 3s 276us/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0423 - val_accuracy: 0.9868\n",
      "Epoch 246/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
      "Epoch 247/1000\n",
      "11512/11512 [==============================] - 3s 277us/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0423 - val_accuracy: 0.9878\n",
      "Epoch 248/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.0445 - val_accuracy: 0.9882\n",
      "Epoch 249/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 0.0440 - val_accuracy: 0.9868\n",
      "Epoch 250/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0426 - val_accuracy: 0.9889\n",
      "Epoch 251/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0442 - val_accuracy: 0.9885\n",
      "Epoch 252/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.0448 - val_accuracy: 0.9889\n",
      "Epoch 253/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
      "Epoch 254/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.0436 - val_accuracy: 0.9871\n",
      "Epoch 255/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 256/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0430 - val_accuracy: 0.9889\n",
      "Epoch 257/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0430 - val_accuracy: 0.9882\n",
      "Epoch 258/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0466 - val_accuracy: 0.9878\n",
      "Epoch 259/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0428 - val_accuracy: 0.9889\n",
      "Epoch 260/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.0428 - val_accuracy: 0.9882\n",
      "Epoch 261/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.0455 - val_accuracy: 0.9871\n",
      "Epoch 262/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 263/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0423 - val_accuracy: 0.9896\n",
      "Epoch 264/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.0427 - val_accuracy: 0.9889\n",
      "Epoch 265/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.0423 - val_accuracy: 0.9885\n",
      "Epoch 266/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "Epoch 267/1000\n",
      "11512/11512 [==============================] - 3s 269us/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0442 - val_accuracy: 0.9885\n",
      "Epoch 268/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0419 - val_accuracy: 0.9882\n",
      "Epoch 269/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
      "Epoch 270/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0448 - val_accuracy: 0.9875\n",
      "Epoch 271/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.0481 - val_accuracy: 0.9882\n",
      "Epoch 272/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0470 - val_accuracy: 0.9878\n",
      "Epoch 273/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
      "Epoch 274/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.0453 - val_accuracy: 0.9871\n",
      "Epoch 275/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.0442 - val_accuracy: 0.9868\n",
      "Epoch 276/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0433 - val_accuracy: 0.9885\n",
      "Epoch 277/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0429 - val_accuracy: 0.9868\n",
      "Epoch 278/1000\n",
      "11512/11512 [==============================] - 4s 328us/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.0464 - val_accuracy: 0.9871\n",
      "Epoch 279/1000\n",
      "11512/11512 [==============================] - 4s 382us/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0457 - val_accuracy: 0.9865\n",
      "Epoch 280/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0466 - val_accuracy: 0.9882\n",
      "Epoch 281/1000\n",
      "11512/11512 [==============================] - 4s 373us/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.0425 - val_accuracy: 0.9875\n",
      "Epoch 282/1000\n",
      "11512/11512 [==============================] - 4s 361us/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.0455 - val_accuracy: 0.9858\n",
      "Epoch 283/1000\n",
      "11512/11512 [==============================] - 4s 364us/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.0432 - val_accuracy: 0.9878\n",
      "Epoch 284/1000\n",
      "11512/11512 [==============================] - 5s 409us/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0499 - val_accuracy: 0.9882\n",
      "Epoch 285/1000\n",
      "11512/11512 [==============================] - 5s 396us/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.0455 - val_accuracy: 0.9875\n",
      "Epoch 286/1000\n",
      "11512/11512 [==============================] - 5s 406us/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0450 - val_accuracy: 0.9875\n",
      "Epoch 287/1000\n",
      "11512/11512 [==============================] - 5s 472us/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.0428 - val_accuracy: 0.9868\n",
      "Epoch 288/1000\n",
      "11512/11512 [==============================] - 5s 404us/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0421 - val_accuracy: 0.9875\n",
      "Epoch 289/1000\n",
      "11512/11512 [==============================] - 4s 384us/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0451 - val_accuracy: 0.9865\n",
      "Epoch 290/1000\n",
      "11512/11512 [==============================] - 4s 388us/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0436 - val_accuracy: 0.9875\n",
      "Epoch 291/1000\n",
      "11512/11512 [==============================] - 4s 348us/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 292/1000\n",
      "11512/11512 [==============================] - 4s 379us/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0461 - val_accuracy: 0.9882\n",
      "Epoch 293/1000\n",
      "11512/11512 [==============================] - 4s 375us/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0439 - val_accuracy: 0.9878\n",
      "Epoch 294/1000\n",
      "11512/11512 [==============================] - 4s 359us/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0423 - val_accuracy: 0.9875\n",
      "Epoch 295/1000\n",
      "11512/11512 [==============================] - 4s 367us/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0444 - val_accuracy: 0.9885\n",
      "Epoch 296/1000\n",
      "11512/11512 [==============================] - 4s 388us/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.0454 - val_accuracy: 0.9865\n",
      "Epoch 297/1000\n",
      "11512/11512 [==============================] - 4s 366us/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 298/1000\n",
      "11512/11512 [==============================] - 4s 364us/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0483 - val_accuracy: 0.9882\n",
      "Epoch 299/1000\n",
      "11512/11512 [==============================] - 4s 386us/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0445 - val_accuracy: 0.9861\n",
      "Epoch 300/1000\n",
      "11512/11512 [==============================] - 4s 374us/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0460 - val_accuracy: 0.9878\n",
      "Epoch 301/1000\n",
      "11512/11512 [==============================] - 4s 361us/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0434 - val_accuracy: 0.9868\n",
      "Epoch 302/1000\n",
      "11512/11512 [==============================] - 4s 352us/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.0448 - val_accuracy: 0.9865\n",
      "Epoch 303/1000\n",
      "11512/11512 [==============================] - 4s 348us/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0433 - val_accuracy: 0.9868\n",
      "Epoch 304/1000\n",
      "11512/11512 [==============================] - 4s 363us/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.0455 - val_accuracy: 0.9875\n",
      "Epoch 305/1000\n",
      "11512/11512 [==============================] - 5s 392us/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 0.0433 - val_accuracy: 0.9871\n",
      "Epoch 306/1000\n",
      "11512/11512 [==============================] - 5s 404us/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 307/1000\n",
      "11512/11512 [==============================] - 4s 370us/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 308/1000\n",
      "11512/11512 [==============================] - 4s 367us/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0449 - val_accuracy: 0.9871\n",
      "Epoch 309/1000\n",
      "11512/11512 [==============================] - 4s 371us/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0464 - val_accuracy: 0.9861\n",
      "Epoch 310/1000\n",
      "11512/11512 [==============================] - 4s 362us/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9889\n",
      "Epoch 311/1000\n",
      "11512/11512 [==============================] - 4s 372us/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
      "Epoch 312/1000\n",
      "11512/11512 [==============================] - 4s 343us/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0446 - val_accuracy: 0.9875\n",
      "Epoch 313/1000\n",
      "11512/11512 [==============================] - 4s 336us/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.0440 - val_accuracy: 0.9865\n",
      "Epoch 314/1000\n",
      "11512/11512 [==============================] - 4s 369us/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.0429 - val_accuracy: 0.9868\n",
      "Epoch 315/1000\n",
      "11512/11512 [==============================] - 4s 357us/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.0444 - val_accuracy: 0.9882\n",
      "Epoch 316/1000\n",
      "11512/11512 [==============================] - 4s 356us/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.0455 - val_accuracy: 0.9868\n",
      "Epoch 317/1000\n",
      "11512/11512 [==============================] - 4s 385us/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 318/1000\n",
      "11512/11512 [==============================] - 4s 366us/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0432 - val_accuracy: 0.9896\n",
      "Epoch 319/1000\n",
      "11512/11512 [==============================] - 4s 353us/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0484 - val_accuracy: 0.9854\n",
      "Epoch 320/1000\n",
      "11512/11512 [==============================] - 4s 364us/step - loss: 0.0257 - accuracy: 0.9910 - val_loss: 0.0438 - val_accuracy: 0.9878\n",
      "Epoch 321/1000\n",
      "11512/11512 [==============================] - 4s 359us/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0432 - val_accuracy: 0.9892\n",
      "Epoch 322/1000\n",
      "11512/11512 [==============================] - 4s 336us/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0502 - val_accuracy: 0.9878\n",
      "Epoch 323/1000\n",
      "11512/11512 [==============================] - 4s 348us/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0443 - val_accuracy: 0.9865\n",
      "Epoch 324/1000\n",
      "11512/11512 [==============================] - 4s 367us/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0417 - val_accuracy: 0.9892\n",
      "Epoch 325/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 326/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0445 - val_accuracy: 0.9875\n",
      "Epoch 327/1000\n",
      "11512/11512 [==============================] - 4s 329us/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0435 - val_accuracy: 0.9882\n",
      "Epoch 328/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 329/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0454 - val_accuracy: 0.9861\n",
      "Epoch 330/1000\n",
      "11512/11512 [==============================] - 4s 332us/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0426 - val_accuracy: 0.9899\n",
      "Epoch 331/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0423 - val_accuracy: 0.9878\n",
      "Epoch 332/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
      "Epoch 333/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0432 - val_accuracy: 0.9878\n",
      "Epoch 334/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 0.0433 - val_accuracy: 0.9889\n",
      "Epoch 335/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0424 - val_accuracy: 0.9878\n",
      "Epoch 336/1000\n",
      "11512/11512 [==============================] - 4s 332us/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0459 - val_accuracy: 0.9882\n",
      "Epoch 337/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0482 - val_accuracy: 0.9885\n",
      "Epoch 338/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 339/1000\n",
      "11512/11512 [==============================] - 4s 321us/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0426 - val_accuracy: 0.9871\n",
      "Epoch 340/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0479 - val_accuracy: 0.9871\n",
      "Epoch 341/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9882\n",
      "Epoch 342/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.0472 - val_accuracy: 0.9871\n",
      "Epoch 343/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0421 - val_accuracy: 0.9871\n",
      "Epoch 344/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.0431 - val_accuracy: 0.9875\n",
      "Epoch 345/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0432 - val_accuracy: 0.9871\n",
      "Epoch 346/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 347/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0439 - val_accuracy: 0.9865\n",
      "Epoch 348/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
      "Epoch 349/1000\n",
      "11512/11512 [==============================] - 4s 329us/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0435 - val_accuracy: 0.9865\n",
      "Epoch 350/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0431 - val_accuracy: 0.9865\n",
      "Epoch 351/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0440 - val_accuracy: 0.9885\n",
      "Epoch 352/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0455 - val_accuracy: 0.9851\n",
      "Epoch 353/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
      "Epoch 354/1000\n",
      "11512/11512 [==============================] - 4s 333us/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0420 - val_accuracy: 0.9868\n",
      "Epoch 355/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0458 - val_accuracy: 0.9854\n",
      "Epoch 356/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0450 - val_accuracy: 0.9885\n",
      "Epoch 357/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0435 - val_accuracy: 0.9865\n",
      "Epoch 358/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0424 - val_accuracy: 0.9868\n",
      "Epoch 359/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0435 - val_accuracy: 0.9865\n",
      "Epoch 360/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0436 - val_accuracy: 0.9878\n",
      "Epoch 361/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0464 - val_accuracy: 0.9882\n",
      "Epoch 362/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0420 - val_accuracy: 0.9868\n",
      "Epoch 363/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0441 - val_accuracy: 0.9882\n",
      "Epoch 364/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 0.0425 - val_accuracy: 0.9892\n",
      "Epoch 365/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.0439 - val_accuracy: 0.9878\n",
      "Epoch 366/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0465 - val_accuracy: 0.9878\n",
      "Epoch 367/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9889\n",
      "Epoch 368/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 369/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9875\n",
      "Epoch 370/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0425 - val_accuracy: 0.9865\n",
      "Epoch 371/1000\n",
      "11512/11512 [==============================] - 4s 336us/step - loss: 0.0253 - accuracy: 0.9910 - val_loss: 0.0431 - val_accuracy: 0.9878\n",
      "Epoch 372/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0436 - val_accuracy: 0.9875\n",
      "Epoch 373/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.0434 - val_accuracy: 0.9871\n",
      "Epoch 374/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 375/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0448 - val_accuracy: 0.9871\n",
      "Epoch 376/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0460 - val_accuracy: 0.9878\n",
      "Epoch 377/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0435 - val_accuracy: 0.9861\n",
      "Epoch 378/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.0410 - val_accuracy: 0.9896\n",
      "Epoch 379/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0434 - val_accuracy: 0.9878\n",
      "Epoch 380/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.0432 - val_accuracy: 0.9878\n",
      "Epoch 381/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 382/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0433 - val_accuracy: 0.9885\n",
      "Epoch 383/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0442 - val_accuracy: 0.9861\n",
      "Epoch 384/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0437 - val_accuracy: 0.9885\n",
      "Epoch 385/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0438 - val_accuracy: 0.9865\n",
      "Epoch 386/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 387/1000\n",
      "11512/11512 [==============================] - 4s 327us/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0447 - val_accuracy: 0.9875\n",
      "Epoch 388/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0414 - val_accuracy: 0.9892\n",
      "Epoch 389/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.0419 - val_accuracy: 0.9871\n",
      "Epoch 390/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0423 - val_accuracy: 0.9875\n",
      "Epoch 391/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.0419 - val_accuracy: 0.9868\n",
      "Epoch 392/1000\n",
      "11512/11512 [==============================] - 4s 336us/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
      "Epoch 393/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0423 - val_accuracy: 0.9885\n",
      "Epoch 394/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0409 - val_accuracy: 0.9889\n",
      "Epoch 395/1000\n",
      "11512/11512 [==============================] - 4s 334us/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0419 - val_accuracy: 0.9882\n",
      "Epoch 396/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.0468 - val_accuracy: 0.9878\n",
      "Epoch 397/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0448 - val_accuracy: 0.9871\n",
      "Epoch 398/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0422 - val_accuracy: 0.9868\n",
      "Epoch 399/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
      "Epoch 400/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0415 - val_accuracy: 0.9882\n",
      "Epoch 401/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0420 - val_accuracy: 0.9878\n",
      "Epoch 402/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0428 - val_accuracy: 0.9875\n",
      "Epoch 403/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0427 - val_accuracy: 0.9865\n",
      "Epoch 404/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0480 - val_accuracy: 0.9882\n",
      "Epoch 405/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0436 - val_accuracy: 0.9865\n",
      "Epoch 406/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 407/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0453 - val_accuracy: 0.9868\n",
      "Epoch 408/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0426 - val_accuracy: 0.9875\n",
      "Epoch 409/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0450 - val_accuracy: 0.9882\n",
      "Epoch 410/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.0438 - val_accuracy: 0.9878\n",
      "Epoch 411/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0430 - val_accuracy: 0.9868\n",
      "Epoch 412/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 413/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.0409 - val_accuracy: 0.9892\n",
      "Epoch 414/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0454 - val_accuracy: 0.9875\n",
      "Epoch 415/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0416 - val_accuracy: 0.9875\n",
      "Epoch 416/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0423 - val_accuracy: 0.9868\n",
      "Epoch 417/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0430 - val_accuracy: 0.9885\n",
      "Epoch 418/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0430 - val_accuracy: 0.9865\n",
      "Epoch 419/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0416 - val_accuracy: 0.9871\n",
      "Epoch 420/1000\n",
      "11512/11512 [==============================] - 3s 277us/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0441 - val_accuracy: 0.9882\n",
      "Epoch 421/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0428 - val_accuracy: 0.9882\n",
      "Epoch 422/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0427 - val_accuracy: 0.9885\n",
      "Epoch 423/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 0.0397 - val_accuracy: 0.9896\n",
      "Epoch 424/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0411 - val_accuracy: 0.9882\n",
      "Epoch 425/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0446 - val_accuracy: 0.9882\n",
      "Epoch 426/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0408 - val_accuracy: 0.9875\n",
      "Epoch 427/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0409 - val_accuracy: 0.9878\n",
      "Epoch 428/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
      "Epoch 429/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0409 - val_accuracy: 0.9868\n",
      "Epoch 430/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0439 - val_accuracy: 0.9875\n",
      "Epoch 431/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 432/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0411 - val_accuracy: 0.9889\n",
      "Epoch 433/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.0425 - val_accuracy: 0.9882\n",
      "Epoch 434/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0418 - val_accuracy: 0.9889\n",
      "Epoch 435/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0406 - val_accuracy: 0.9871\n",
      "Epoch 436/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0428 - val_accuracy: 0.9875\n",
      "Epoch 437/1000\n",
      "11512/11512 [==============================] - 4s 321us/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0463 - val_accuracy: 0.9871\n",
      "Epoch 438/1000\n",
      "11512/11512 [==============================] - 4s 330us/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0465 - val_accuracy: 0.9882\n",
      "Epoch 439/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.0447 - val_accuracy: 0.9882\n",
      "Epoch 440/1000\n",
      "11512/11512 [==============================] - 4s 333us/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0408 - val_accuracy: 0.9885\n",
      "Epoch 441/1000\n",
      "11512/11512 [==============================] - 4s 339us/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0399 - val_accuracy: 0.9889\n",
      "Epoch 442/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0441 - val_accuracy: 0.9878\n",
      "Epoch 443/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0427 - val_accuracy: 0.9871\n",
      "Epoch 444/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0418 - val_accuracy: 0.9882\n",
      "Epoch 445/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 446/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 447/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 448/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0433 - val_accuracy: 0.9871\n",
      "Epoch 449/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0443 - val_accuracy: 0.9892\n",
      "Epoch 450/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0437 - val_accuracy: 0.9865\n",
      "Epoch 451/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0416 - val_accuracy: 0.9896\n",
      "Epoch 452/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.0410 - val_accuracy: 0.9882\n",
      "Epoch 453/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0413 - val_accuracy: 0.9868\n",
      "Epoch 454/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0404 - val_accuracy: 0.9885\n",
      "Epoch 455/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0414 - val_accuracy: 0.9865\n",
      "Epoch 456/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
      "Epoch 457/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.0451 - val_accuracy: 0.9868\n",
      "Epoch 458/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0422 - val_accuracy: 0.9878\n",
      "Epoch 459/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.0445 - val_accuracy: 0.9865\n",
      "Epoch 460/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.0400 - val_accuracy: 0.9885\n",
      "Epoch 461/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "Epoch 462/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9878\n",
      "Epoch 463/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0404 - val_accuracy: 0.9868\n",
      "Epoch 464/1000\n",
      "11512/11512 [==============================] - 3s 269us/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0414 - val_accuracy: 0.9878\n",
      "Epoch 465/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0424 - val_accuracy: 0.9889\n",
      "Epoch 466/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9868\n",
      "Epoch 467/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0399 - val_accuracy: 0.9892\n",
      "Epoch 468/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 469/1000\n",
      "11512/11512 [==============================] - 4s 321us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0413 - val_accuracy: 0.9871\n",
      "Epoch 470/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0412 - val_accuracy: 0.9882\n",
      "Epoch 471/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0427 - val_accuracy: 0.9871\n",
      "Epoch 472/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0403 - val_accuracy: 0.9889\n",
      "Epoch 473/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0398 - val_accuracy: 0.9896\n",
      "Epoch 474/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0423 - val_accuracy: 0.9878\n",
      "Epoch 475/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0398 - val_accuracy: 0.9889\n",
      "Epoch 476/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0401 - val_accuracy: 0.9896\n",
      "Epoch 477/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0409 - val_accuracy: 0.9868\n",
      "Epoch 478/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
      "Epoch 479/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.0413 - val_accuracy: 0.9889\n",
      "Epoch 480/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0422 - val_accuracy: 0.9865\n",
      "Epoch 481/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0425 - val_accuracy: 0.9861\n",
      "Epoch 482/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
      "Epoch 483/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 484/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0417 - val_accuracy: 0.9878\n",
      "Epoch 485/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
      "Epoch 486/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 487/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0398 - val_accuracy: 0.9896\n",
      "Epoch 488/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0393 - val_accuracy: 0.9899\n",
      "Epoch 489/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0447 - val_accuracy: 0.9868\n",
      "Epoch 490/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0408 - val_accuracy: 0.9878\n",
      "Epoch 491/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.0435 - val_accuracy: 0.9858\n",
      "Epoch 492/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 493/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "Epoch 494/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.0401 - val_accuracy: 0.9878\n",
      "Epoch 495/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
      "Epoch 496/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0247 - accuracy: 0.9918 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
      "Epoch 497/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9858\n",
      "Epoch 498/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0454 - val_accuracy: 0.9865\n",
      "Epoch 499/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0438 - val_accuracy: 0.9875\n",
      "Epoch 500/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9878\n",
      "Epoch 501/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.0425 - val_accuracy: 0.9892\n",
      "Epoch 502/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 503/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0400 - val_accuracy: 0.9896\n",
      "Epoch 504/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0427 - val_accuracy: 0.9878\n",
      "Epoch 505/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0439 - val_accuracy: 0.9868\n",
      "Epoch 506/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0464 - val_accuracy: 0.9878\n",
      "Epoch 507/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0406 - val_accuracy: 0.9889\n",
      "Epoch 508/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0436 - val_accuracy: 0.9875\n",
      "Epoch 509/1000\n",
      "11512/11512 [==============================] - 3s 277us/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
      "Epoch 510/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0410 - val_accuracy: 0.9889\n",
      "Epoch 511/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0410 - val_accuracy: 0.9868\n",
      "Epoch 512/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0415 - val_accuracy: 0.9875\n",
      "Epoch 513/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 514/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 515/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9868\n",
      "Epoch 516/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0413 - val_accuracy: 0.9865\n",
      "Epoch 517/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 518/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0412 - val_accuracy: 0.9871\n",
      "Epoch 519/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0403 - val_accuracy: 0.9889\n",
      "Epoch 520/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9882\n",
      "Epoch 521/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0410 - val_accuracy: 0.9882\n",
      "Epoch 522/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0403 - val_accuracy: 0.9885\n",
      "Epoch 523/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
      "Epoch 524/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0399 - val_accuracy: 0.9892\n",
      "Epoch 525/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0426 - val_accuracy: 0.9861\n",
      "Epoch 526/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9861\n",
      "Epoch 527/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0391 - val_accuracy: 0.9896\n",
      "Epoch 528/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0480 - val_accuracy: 0.9885\n",
      "Epoch 529/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0435 - val_accuracy: 0.9878\n",
      "Epoch 530/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 531/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.0394 - val_accuracy: 0.9892\n",
      "Epoch 532/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0408 - val_accuracy: 0.9875\n",
      "Epoch 533/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
      "Epoch 534/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0427 - val_accuracy: 0.9875\n",
      "Epoch 535/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 0.0442 - val_accuracy: 0.9875\n",
      "Epoch 536/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 537/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0397 - val_accuracy: 0.9896\n",
      "Epoch 538/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.0408 - val_accuracy: 0.9892\n",
      "Epoch 539/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0434 - val_accuracy: 0.9861\n",
      "Epoch 540/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0425 - val_accuracy: 0.9868\n",
      "Epoch 541/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0411 - val_accuracy: 0.9885\n",
      "Epoch 542/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0400 - val_accuracy: 0.9878\n",
      "Epoch 543/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0394 - val_accuracy: 0.9875\n",
      "Epoch 544/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0443 - val_accuracy: 0.9847\n",
      "Epoch 545/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0406 - val_accuracy: 0.9889\n",
      "Epoch 546/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0407 - val_accuracy: 0.9871\n",
      "Epoch 547/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0433 - val_accuracy: 0.9875\n",
      "Epoch 548/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
      "Epoch 549/1000\n",
      "11512/11512 [==============================] - 4s 333us/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
      "Epoch 550/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0398 - val_accuracy: 0.9889\n",
      "Epoch 551/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 552/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
      "Epoch 553/1000\n",
      "11512/11512 [==============================] - 3s 275us/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0410 - val_accuracy: 0.9875\n",
      "Epoch 554/1000\n",
      "11512/11512 [==============================] - 4s 327us/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0426 - val_accuracy: 0.9875\n",
      "Epoch 555/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.0470 - val_accuracy: 0.9882\n",
      "Epoch 556/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0405 - val_accuracy: 0.9899\n",
      "Epoch 557/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 558/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 0.0420 - val_accuracy: 0.9878\n",
      "Epoch 559/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0413 - val_accuracy: 0.9871\n",
      "Epoch 560/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0408 - val_accuracy: 0.9889\n",
      "Epoch 561/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
      "Epoch 562/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
      "Epoch 563/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 564/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 565/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0393 - val_accuracy: 0.9892\n",
      "Epoch 566/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0402 - val_accuracy: 0.9875\n",
      "Epoch 567/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0406 - val_accuracy: 0.9896\n",
      "Epoch 568/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
      "Epoch 569/1000\n",
      "11512/11512 [==============================] - 4s 337us/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0427 - val_accuracy: 0.9885\n",
      "Epoch 570/1000\n",
      "11512/11512 [==============================] - 4s 351us/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 571/1000\n",
      "11512/11512 [==============================] - 4s 342us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0395 - val_accuracy: 0.9889\n",
      "Epoch 572/1000\n",
      "11512/11512 [==============================] - 4s 319us/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0478 - val_accuracy: 0.9882\n",
      "Epoch 573/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0417 - val_accuracy: 0.9878\n",
      "Epoch 574/1000\n",
      "11512/11512 [==============================] - 4s 328us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0402 - val_accuracy: 0.9885\n",
      "Epoch 575/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.0438 - val_accuracy: 0.9861\n",
      "Epoch 576/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0402 - val_accuracy: 0.9871\n",
      "Epoch 577/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "Epoch 578/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "Epoch 579/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.0431 - val_accuracy: 0.9871\n",
      "Epoch 580/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0413 - val_accuracy: 0.9875\n",
      "Epoch 581/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0396 - val_accuracy: 0.9896\n",
      "Epoch 582/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
      "Epoch 583/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0397 - val_accuracy: 0.9892\n",
      "Epoch 584/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0404 - val_accuracy: 0.9871\n",
      "Epoch 585/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0419 - val_accuracy: 0.9871\n",
      "Epoch 586/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0395 - val_accuracy: 0.9878\n",
      "Epoch 587/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0412 - val_accuracy: 0.9889\n",
      "Epoch 588/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0393 - val_accuracy: 0.9885\n",
      "Epoch 589/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 590/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0394 - val_accuracy: 0.9899\n",
      "Epoch 591/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0406 - val_accuracy: 0.9885\n",
      "Epoch 592/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.0420 - val_accuracy: 0.9871\n",
      "Epoch 593/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9885\n",
      "Epoch 594/1000\n",
      "11512/11512 [==============================] - 4s 330us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0400 - val_accuracy: 0.9889\n",
      "Epoch 595/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0390 - val_accuracy: 0.9889\n",
      "Epoch 596/1000\n",
      "11512/11512 [==============================] - 4s 326us/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0406 - val_accuracy: 0.9868\n",
      "Epoch 597/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9892\n",
      "Epoch 598/1000\n",
      "11512/11512 [==============================] - 4s 321us/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0423 - val_accuracy: 0.9871\n",
      "Epoch 599/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0415 - val_accuracy: 0.9882\n",
      "Epoch 600/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.0407 - val_accuracy: 0.9889\n",
      "Epoch 601/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0432 - val_accuracy: 0.9858\n",
      "Epoch 602/1000\n",
      "11512/11512 [==============================] - 4s 314us/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0412 - val_accuracy: 0.9885\n",
      "Epoch 603/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 604/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
      "Epoch 605/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0410 - val_accuracy: 0.9892\n",
      "Epoch 606/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0404 - val_accuracy: 0.9861\n",
      "Epoch 607/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0423 - val_accuracy: 0.9882\n",
      "Epoch 608/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
      "Epoch 609/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 0.0407 - val_accuracy: 0.9865\n",
      "Epoch 610/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0460 - val_accuracy: 0.9861\n",
      "Epoch 611/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
      "Epoch 612/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0397 - val_accuracy: 0.9889\n",
      "Epoch 613/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.0402 - val_accuracy: 0.9882\n",
      "Epoch 614/1000\n",
      "11512/11512 [==============================] - 4s 325us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0403 - val_accuracy: 0.9889\n",
      "Epoch 615/1000\n",
      "11512/11512 [==============================] - 4s 327us/step - loss: 0.0244 - accuracy: 0.9914 - val_loss: 0.0399 - val_accuracy: 0.9889\n",
      "Epoch 616/1000\n",
      "11512/11512 [==============================] - 4s 325us/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0413 - val_accuracy: 0.9889\n",
      "Epoch 617/1000\n",
      "11512/11512 [==============================] - 4s 340us/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0392 - val_accuracy: 0.9875\n",
      "Epoch 618/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0407 - val_accuracy: 0.9885\n",
      "Epoch 619/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0401 - val_accuracy: 0.9875\n",
      "Epoch 620/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
      "Epoch 621/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0418 - val_accuracy: 0.9892\n",
      "Epoch 622/1000\n",
      "11512/11512 [==============================] - 4s 334us/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0402 - val_accuracy: 0.9889\n",
      "Epoch 623/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.0424 - val_accuracy: 0.9871\n",
      "Epoch 624/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.0398 - val_accuracy: 0.9875\n",
      "Epoch 625/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0437 - val_accuracy: 0.9871\n",
      "Epoch 626/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
      "Epoch 627/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0442 - val_accuracy: 0.9851\n",
      "Epoch 628/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9875\n",
      "Epoch 629/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0408 - val_accuracy: 0.9878\n",
      "Epoch 630/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0447 - val_accuracy: 0.9861\n",
      "Epoch 631/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0436 - val_accuracy: 0.9892\n",
      "Epoch 632/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0407 - val_accuracy: 0.9878\n",
      "Epoch 633/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 634/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0418 - val_accuracy: 0.9868\n",
      "Epoch 635/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.0395 - val_accuracy: 0.9889\n",
      "Epoch 636/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0435 - val_accuracy: 0.9885\n",
      "Epoch 637/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 638/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0435 - val_accuracy: 0.9882\n",
      "Epoch 639/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
      "Epoch 640/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
      "Epoch 641/1000\n",
      "11512/11512 [==============================] - 3s 260us/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0401 - val_accuracy: 0.9896\n",
      "Epoch 642/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0392 - val_accuracy: 0.9889\n",
      "Epoch 643/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 644/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0422 - val_accuracy: 0.9882\n",
      "Epoch 645/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0426 - val_accuracy: 0.9878\n",
      "Epoch 646/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0406 - val_accuracy: 0.9889\n",
      "Epoch 647/1000\n",
      "11512/11512 [==============================] - 3s 273us/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
      "Epoch 648/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0396 - val_accuracy: 0.9896\n",
      "Epoch 649/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 650/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0419 - val_accuracy: 0.9858\n",
      "Epoch 651/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0407 - val_accuracy: 0.9882\n",
      "Epoch 652/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0403 - val_accuracy: 0.9882\n",
      "Epoch 653/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0403 - val_accuracy: 0.9878\n",
      "Epoch 654/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.0420 - val_accuracy: 0.9868\n",
      "Epoch 655/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
      "Epoch 656/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0403 - val_accuracy: 0.9871\n",
      "Epoch 657/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0415 - val_accuracy: 0.9889\n",
      "Epoch 658/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0393 - val_accuracy: 0.9896\n",
      "Epoch 659/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0390 - val_accuracy: 0.9882\n",
      "Epoch 660/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0383 - val_accuracy: 0.9896\n",
      "Epoch 661/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0387 - val_accuracy: 0.9878\n",
      "Epoch 662/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0412 - val_accuracy: 0.9865\n",
      "Epoch 663/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0392 - val_accuracy: 0.9892\n",
      "Epoch 664/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 665/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0418 - val_accuracy: 0.9885\n",
      "Epoch 666/1000\n",
      "11512/11512 [==============================] - 3s 273us/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0412 - val_accuracy: 0.9878\n",
      "Epoch 667/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0416 - val_accuracy: 0.9871\n",
      "Epoch 668/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0445 - val_accuracy: 0.9885\n",
      "Epoch 669/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.0420 - val_accuracy: 0.9882\n",
      "Epoch 670/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.0400 - val_accuracy: 0.9882\n",
      "Epoch 671/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0438 - val_accuracy: 0.9871\n",
      "Epoch 672/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0401 - val_accuracy: 0.9871\n",
      "Epoch 673/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0415 - val_accuracy: 0.9885\n",
      "Epoch 674/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0393 - val_accuracy: 0.9899\n",
      "Epoch 675/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 676/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0397 - val_accuracy: 0.9892\n",
      "Epoch 677/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0412 - val_accuracy: 0.9865\n",
      "Epoch 678/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0394 - val_accuracy: 0.9875\n",
      "Epoch 679/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0402 - val_accuracy: 0.9878\n",
      "Epoch 680/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 681/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0448 - val_accuracy: 0.9868\n",
      "Epoch 682/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0416 - val_accuracy: 0.9858\n",
      "Epoch 683/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0242 - accuracy: 0.9914 - val_loss: 0.0422 - val_accuracy: 0.9878\n",
      "Epoch 684/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0409 - val_accuracy: 0.9865\n",
      "Epoch 685/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 686/1000\n",
      "11512/11512 [==============================] - 3s 254us/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0391 - val_accuracy: 0.9885\n",
      "Epoch 687/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 688/1000\n",
      "11512/11512 [==============================] - 3s 275us/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.0422 - val_accuracy: 0.9882\n",
      "Epoch 689/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0407 - val_accuracy: 0.9882\n",
      "Epoch 690/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.0401 - val_accuracy: 0.9878\n",
      "Epoch 691/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0418 - val_accuracy: 0.9875\n",
      "Epoch 692/1000\n",
      "11512/11512 [==============================] - 3s 273us/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0410 - val_accuracy: 0.9875\n",
      "Epoch 693/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0240 - accuracy: 0.9914 - val_loss: 0.0418 - val_accuracy: 0.9875\n",
      "Epoch 694/1000\n",
      "11512/11512 [==============================] - 3s 301us/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0408 - val_accuracy: 0.9871\n",
      "Epoch 695/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
      "Epoch 696/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 697/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0413 - val_accuracy: 0.9865\n",
      "Epoch 698/1000\n",
      "11512/11512 [==============================] - 4s 331us/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0446 - val_accuracy: 0.9882\n",
      "Epoch 699/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0395 - val_accuracy: 0.9889\n",
      "Epoch 700/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0397 - val_accuracy: 0.9875\n",
      "Epoch 701/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.0402 - val_accuracy: 0.9889\n",
      "Epoch 702/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0440 - val_accuracy: 0.9858\n",
      "Epoch 703/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0435 - val_accuracy: 0.9861\n",
      "Epoch 704/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0407 - val_accuracy: 0.9871\n",
      "Epoch 705/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0422 - val_accuracy: 0.9858\n",
      "Epoch 706/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0435 - val_accuracy: 0.9871\n",
      "Epoch 707/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0407 - val_accuracy: 0.9878\n",
      "Epoch 708/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0389 - val_accuracy: 0.9889\n",
      "Epoch 709/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.0391 - val_accuracy: 0.9889\n",
      "Epoch 710/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0411 - val_accuracy: 0.9871\n",
      "Epoch 711/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0409 - val_accuracy: 0.9868\n",
      "Epoch 712/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0409 - val_accuracy: 0.9878\n",
      "Epoch 713/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0428 - val_accuracy: 0.9868\n",
      "Epoch 714/1000\n",
      "11512/11512 [==============================] - 3s 276us/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0398 - val_accuracy: 0.9878\n",
      "Epoch 715/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0459 - val_accuracy: 0.9882\n",
      "Epoch 716/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 717/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0413 - val_accuracy: 0.9885\n",
      "Epoch 718/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0400 - val_accuracy: 0.9889\n",
      "Epoch 719/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0421 - val_accuracy: 0.9854\n",
      "Epoch 720/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0418 - val_accuracy: 0.9882\n",
      "Epoch 721/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.0397 - val_accuracy: 0.9875\n",
      "Epoch 722/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0410 - val_accuracy: 0.9878\n",
      "Epoch 723/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0407 - val_accuracy: 0.9882\n",
      "Epoch 724/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0409 - val_accuracy: 0.9882\n",
      "Epoch 725/1000\n",
      "11512/11512 [==============================] - 4s 330us/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0429 - val_accuracy: 0.9871\n",
      "Epoch 726/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0398 - val_accuracy: 0.9868\n",
      "Epoch 727/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0423 - val_accuracy: 0.9885\n",
      "Epoch 728/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0412 - val_accuracy: 0.9875\n",
      "Epoch 729/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 730/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0396 - val_accuracy: 0.9871\n",
      "Epoch 731/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0383 - val_accuracy: 0.9896\n",
      "Epoch 732/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0386 - val_accuracy: 0.9878\n",
      "Epoch 733/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0396 - val_accuracy: 0.9889\n",
      "Epoch 734/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
      "Epoch 735/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 736/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0416 - val_accuracy: 0.9868\n",
      "Epoch 737/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 0.0388 - val_accuracy: 0.9885\n",
      "Epoch 738/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0421 - val_accuracy: 0.9861\n",
      "Epoch 739/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.0421 - val_accuracy: 0.9878\n",
      "Epoch 740/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.0404 - val_accuracy: 0.9885\n",
      "Epoch 741/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.0398 - val_accuracy: 0.9882\n",
      "Epoch 742/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0411 - val_accuracy: 0.9889\n",
      "Epoch 743/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0419 - val_accuracy: 0.9878\n",
      "Epoch 744/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0442 - val_accuracy: 0.9889\n",
      "Epoch 745/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0406 - val_accuracy: 0.9882\n",
      "Epoch 746/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9896\n",
      "Epoch 747/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0402 - val_accuracy: 0.9885\n",
      "Epoch 748/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0420 - val_accuracy: 0.9878\n",
      "Epoch 749/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0413 - val_accuracy: 0.9885\n",
      "Epoch 750/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "Epoch 751/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0389 - val_accuracy: 0.9889\n",
      "Epoch 752/1000\n",
      "11512/11512 [==============================] - 3s 277us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
      "Epoch 753/1000\n",
      "11512/11512 [==============================] - 3s 276us/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.0410 - val_accuracy: 0.9871\n",
      "Epoch 754/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
      "Epoch 755/1000\n",
      "11512/11512 [==============================] - 3s 271us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 756/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.0400 - val_accuracy: 0.9889\n",
      "Epoch 757/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0410 - val_accuracy: 0.9889\n",
      "Epoch 758/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0412 - val_accuracy: 0.9868\n",
      "Epoch 759/1000\n",
      "11512/11512 [==============================] - 3s 275us/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0426 - val_accuracy: 0.9882\n",
      "Epoch 760/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0443 - val_accuracy: 0.9858\n",
      "Epoch 761/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
      "Epoch 762/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0415 - val_accuracy: 0.9875\n",
      "Epoch 763/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0392 - val_accuracy: 0.9882\n",
      "Epoch 764/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.0422 - val_accuracy: 0.9885\n",
      "Epoch 765/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0419 - val_accuracy: 0.9878\n",
      "Epoch 766/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.0442 - val_accuracy: 0.9851\n",
      "Epoch 767/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0413 - val_accuracy: 0.9871\n",
      "Epoch 768/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0399 - val_accuracy: 0.9889\n",
      "Epoch 769/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0396 - val_accuracy: 0.9892\n",
      "Epoch 770/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0396 - val_accuracy: 0.9882\n",
      "Epoch 771/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 772/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0396 - val_accuracy: 0.9889\n",
      "Epoch 773/1000\n",
      "11512/11512 [==============================] - 4s 307us/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0397 - val_accuracy: 0.9885\n",
      "Epoch 774/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
      "Epoch 775/1000\n",
      "11512/11512 [==============================] - 3s 267us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0413 - val_accuracy: 0.9885\n",
      "Epoch 776/1000\n",
      "11512/11512 [==============================] - 3s 303us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0400 - val_accuracy: 0.9875\n",
      "Epoch 777/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0399 - val_accuracy: 0.9889\n",
      "Epoch 778/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0410 - val_accuracy: 0.9885\n",
      "Epoch 779/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.0400 - val_accuracy: 0.9871\n",
      "Epoch 780/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0448 - val_accuracy: 0.9885\n",
      "Epoch 781/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9875\n",
      "Epoch 782/1000\n",
      "11512/11512 [==============================] - 4s 334us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0396 - val_accuracy: 0.9885\n",
      "Epoch 783/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0415 - val_accuracy: 0.9875\n",
      "Epoch 784/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0403 - val_accuracy: 0.9871\n",
      "Epoch 785/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0402 - val_accuracy: 0.9871\n",
      "Epoch 786/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0412 - val_accuracy: 0.9868\n",
      "Epoch 787/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0403 - val_accuracy: 0.9871\n",
      "Epoch 788/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.0408 - val_accuracy: 0.9882\n",
      "Epoch 789/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0413 - val_accuracy: 0.9889\n",
      "Epoch 790/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0387 - val_accuracy: 0.9882\n",
      "Epoch 791/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 0.0393 - val_accuracy: 0.9885\n",
      "Epoch 792/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0387 - val_accuracy: 0.9896\n",
      "Epoch 793/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 794/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0417 - val_accuracy: 0.9882\n",
      "Epoch 795/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
      "Epoch 796/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0417 - val_accuracy: 0.9882\n",
      "Epoch 797/1000\n",
      "11512/11512 [==============================] - 3s 267us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0408 - val_accuracy: 0.9871\n",
      "Epoch 798/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0402 - val_accuracy: 0.9871\n",
      "Epoch 799/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
      "Epoch 800/1000\n",
      "11512/11512 [==============================] - 3s 277us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0391 - val_accuracy: 0.9889\n",
      "Epoch 801/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0415 - val_accuracy: 0.9882\n",
      "Epoch 802/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0392 - val_accuracy: 0.9892\n",
      "Epoch 803/1000\n",
      "11512/11512 [==============================] - 3s 269us/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.0405 - val_accuracy: 0.9871\n",
      "Epoch 804/1000\n",
      "11512/11512 [==============================] - 3s 271us/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.0395 - val_accuracy: 0.9875\n",
      "Epoch 805/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0426 - val_accuracy: 0.9858\n",
      "Epoch 806/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9865\n",
      "Epoch 807/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0395 - val_accuracy: 0.9878\n",
      "Epoch 808/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
      "Epoch 809/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.0380 - val_accuracy: 0.9889\n",
      "Epoch 810/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0414 - val_accuracy: 0.9871\n",
      "Epoch 811/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0390 - val_accuracy: 0.9882\n",
      "Epoch 812/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
      "Epoch 813/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0398 - val_accuracy: 0.9875\n",
      "Epoch 814/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 815/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0418 - val_accuracy: 0.9858\n",
      "Epoch 816/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 817/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.0404 - val_accuracy: 0.9871\n",
      "Epoch 818/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0405 - val_accuracy: 0.9882\n",
      "Epoch 819/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0414 - val_accuracy: 0.9885\n",
      "Epoch 820/1000\n",
      "11512/11512 [==============================] - 3s 255us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 821/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.0401 - val_accuracy: 0.9885\n",
      "Epoch 822/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9882\n",
      "Epoch 823/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9878\n",
      "Epoch 824/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0426 - val_accuracy: 0.9871\n",
      "Epoch 825/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0242 - accuracy: 0.9907 - val_loss: 0.0408 - val_accuracy: 0.9875\n",
      "Epoch 826/1000\n",
      "11512/11512 [==============================] - 3s 270us/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.0407 - val_accuracy: 0.9882\n",
      "Epoch 827/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.0386 - val_accuracy: 0.9896\n",
      "Epoch 828/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0239 - accuracy: 0.9911 - val_loss: 0.0446 - val_accuracy: 0.9875\n",
      "Epoch 829/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
      "Epoch 830/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0236 - accuracy: 0.9912 - val_loss: 0.0427 - val_accuracy: 0.9878\n",
      "Epoch 831/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0427 - val_accuracy: 0.9878\n",
      "Epoch 832/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0402 - val_accuracy: 0.9889\n",
      "Epoch 833/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0427 - val_accuracy: 0.9892\n",
      "Epoch 834/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0436 - val_accuracy: 0.9868\n",
      "Epoch 835/1000\n",
      "11512/11512 [==============================] - 3s 272us/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0398 - val_accuracy: 0.9875\n",
      "Epoch 836/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0388 - val_accuracy: 0.9896\n",
      "Epoch 837/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0410 - val_accuracy: 0.9882\n",
      "Epoch 838/1000\n",
      "11512/11512 [==============================] - 4s 312us/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.0413 - val_accuracy: 0.9878\n",
      "Epoch 839/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.0414 - val_accuracy: 0.9885\n",
      "Epoch 840/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 841/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0409 - val_accuracy: 0.9885\n",
      "Epoch 842/1000\n",
      "11512/11512 [==============================] - 3s 251us/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0389 - val_accuracy: 0.9882\n",
      "Epoch 843/1000\n",
      "11512/11512 [==============================] - 3s 271us/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0426 - val_accuracy: 0.9868\n",
      "Epoch 844/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0402 - val_accuracy: 0.9878\n",
      "Epoch 845/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
      "Epoch 846/1000\n",
      "11512/11512 [==============================] - 3s 277us/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.0407 - val_accuracy: 0.9875\n",
      "Epoch 847/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0413 - val_accuracy: 0.9882\n",
      "Epoch 848/1000\n",
      "11512/11512 [==============================] - 3s 273us/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0416 - val_accuracy: 0.9868\n",
      "Epoch 849/1000\n",
      "11512/11512 [==============================] - 3s 275us/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0412 - val_accuracy: 0.9875\n",
      "Epoch 850/1000\n",
      "11512/11512 [==============================] - 4s 339us/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.0424 - val_accuracy: 0.9871\n",
      "Epoch 851/1000\n",
      "11512/11512 [==============================] - 4s 320us/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.0413 - val_accuracy: 0.9885\n",
      "Epoch 852/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0384 - val_accuracy: 0.9889\n",
      "Epoch 853/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
      "Epoch 854/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0408 - val_accuracy: 0.9882\n",
      "Epoch 855/1000\n",
      "11512/11512 [==============================] - 4s 304us/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.0419 - val_accuracy: 0.9854\n",
      "Epoch 856/1000\n",
      "11512/11512 [==============================] - 3s 285us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0407 - val_accuracy: 0.9871\n",
      "Epoch 857/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.0385 - val_accuracy: 0.9882\n",
      "Epoch 858/1000\n",
      "11512/11512 [==============================] - 4s 362us/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0388 - val_accuracy: 0.9896\n",
      "Epoch 859/1000\n",
      "11512/11512 [==============================] - 4s 368us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 860/1000\n",
      "11512/11512 [==============================] - 5s 430us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0391 - val_accuracy: 0.9896\n",
      "Epoch 861/1000\n",
      "11512/11512 [==============================] - 4s 338us/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0401 - val_accuracy: 0.9892\n",
      "Epoch 862/1000\n",
      "11512/11512 [==============================] - 4s 331us/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
      "Epoch 863/1000\n",
      "11512/11512 [==============================] - 4s 339us/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0398 - val_accuracy: 0.9868\n",
      "Epoch 864/1000\n",
      "11512/11512 [==============================] - 4s 332us/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0391 - val_accuracy: 0.9878\n",
      "Epoch 865/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0390 - val_accuracy: 0.9875\n",
      "Epoch 866/1000\n",
      "11512/11512 [==============================] - 4s 323us/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0394 - val_accuracy: 0.9885\n",
      "Epoch 867/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0400 - val_accuracy: 0.9878\n",
      "Epoch 868/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 0.0416 - val_accuracy: 0.9871\n",
      "Epoch 869/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
      "Epoch 870/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0397 - val_accuracy: 0.9885\n",
      "Epoch 871/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0389 - val_accuracy: 0.9885\n",
      "Epoch 872/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0415 - val_accuracy: 0.9875\n",
      "Epoch 873/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
      "Epoch 874/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9892\n",
      "Epoch 875/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9878\n",
      "Epoch 876/1000\n",
      "11512/11512 [==============================] - 3s 297us/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.0389 - val_accuracy: 0.9882\n",
      "Epoch 877/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
      "Epoch 878/1000\n",
      "11512/11512 [==============================] - 3s 287us/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0390 - val_accuracy: 0.9889\n",
      "Epoch 879/1000\n",
      "11512/11512 [==============================] - 3s 275us/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.0415 - val_accuracy: 0.9875\n",
      "Epoch 880/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 881/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0424 - val_accuracy: 0.9865\n",
      "Epoch 882/1000\n",
      "11512/11512 [==============================] - 3s 293us/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0407 - val_accuracy: 0.9885\n",
      "Epoch 883/1000\n",
      "11512/11512 [==============================] - 4s 311us/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0382 - val_accuracy: 0.9896\n",
      "Epoch 884/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0398 - val_accuracy: 0.9878\n",
      "Epoch 885/1000\n",
      "11512/11512 [==============================] - 3s 290us/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.0410 - val_accuracy: 0.9875\n",
      "Epoch 886/1000\n",
      "11512/11512 [==============================] - 4s 305us/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.0430 - val_accuracy: 0.9868\n",
      "Epoch 887/1000\n",
      "11512/11512 [==============================] - 3s 249us/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0409 - val_accuracy: 0.9875\n",
      "Epoch 888/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0400 - val_accuracy: 0.9885\n",
      "Epoch 889/1000\n",
      "11512/11512 [==============================] - 4s 315us/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0418 - val_accuracy: 0.9882\n",
      "Epoch 890/1000\n",
      "11512/11512 [==============================] - 4s 344us/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.0401 - val_accuracy: 0.9871\n",
      "Epoch 891/1000\n",
      "11512/11512 [==============================] - 4s 377us/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.0426 - val_accuracy: 0.9861\n",
      "Epoch 892/1000\n",
      "11512/11512 [==============================] - 4s 360us/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0450 - val_accuracy: 0.9865\n",
      "Epoch 893/1000\n",
      "11512/11512 [==============================] - 4s 324us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0429 - val_accuracy: 0.9875\n",
      "Epoch 894/1000\n",
      "11512/11512 [==============================] - 4s 328us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0394 - val_accuracy: 0.9868\n",
      "Epoch 895/1000\n",
      "11512/11512 [==============================] - 4s 346us/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0399 - val_accuracy: 0.9868\n",
      "Epoch 896/1000\n",
      "11512/11512 [==============================] - 4s 343us/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "Epoch 897/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
      "Epoch 898/1000\n",
      "11512/11512 [==============================] - 4s 337us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0414 - val_accuracy: 0.9871\n",
      "Epoch 899/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 900/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.0417 - val_accuracy: 0.9868\n",
      "Epoch 901/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0429 - val_accuracy: 0.9889\n",
      "Epoch 902/1000\n",
      "11512/11512 [==============================] - 4s 325us/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0386 - val_accuracy: 0.9892\n",
      "Epoch 903/1000\n",
      "11512/11512 [==============================] - 5s 396us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0400 - val_accuracy: 0.9868\n",
      "Epoch 904/1000\n",
      "11512/11512 [==============================] - 5s 422us/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
      "Epoch 905/1000\n",
      "11512/11512 [==============================] - 6s 487us/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0392 - val_accuracy: 0.9878\n",
      "Epoch 906/1000\n",
      "11512/11512 [==============================] - 4s 330us/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
      "Epoch 907/1000\n",
      "11512/11512 [==============================] - 4s 383us/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0421 - val_accuracy: 0.9885\n",
      "Epoch 908/1000\n",
      "11512/11512 [==============================] - 4s 341us/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
      "Epoch 909/1000\n",
      "11512/11512 [==============================] - 5s 435us/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.0443 - val_accuracy: 0.9878\n",
      "Epoch 910/1000\n",
      "11512/11512 [==============================] - 5s 410us/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9882\n",
      "Epoch 911/1000\n",
      "11512/11512 [==============================] - 5s 430us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0404 - val_accuracy: 0.9882\n",
      "Epoch 912/1000\n",
      "11512/11512 [==============================] - 4s 366us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0439 - val_accuracy: 0.9882\n",
      "Epoch 913/1000\n",
      "11512/11512 [==============================] - 5s 422us/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0415 - val_accuracy: 0.9865\n",
      "Epoch 914/1000\n",
      "11512/11512 [==============================] - 4s 360us/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0453 - val_accuracy: 0.9882\n",
      "Epoch 915/1000\n",
      "11512/11512 [==============================] - 4s 377us/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
      "Epoch 916/1000\n",
      "11512/11512 [==============================] - 4s 347us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0410 - val_accuracy: 0.9865\n",
      "Epoch 917/1000\n",
      "11512/11512 [==============================] - 4s 338us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0391 - val_accuracy: 0.9889\n",
      "Epoch 918/1000\n",
      "11512/11512 [==============================] - 3s 302us/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.0428 - val_accuracy: 0.9878\n",
      "Epoch 919/1000\n",
      "11512/11512 [==============================] - 3s 272us/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0401 - val_accuracy: 0.9875\n",
      "Epoch 920/1000\n",
      "11512/11512 [==============================] - 3s 284us/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 0.0408 - val_accuracy: 0.9871\n",
      "Epoch 921/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.0389 - val_accuracy: 0.9896\n",
      "Epoch 922/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0405 - val_accuracy: 0.9868\n",
      "Epoch 923/1000\n",
      "11512/11512 [==============================] - 3s 254us/step - loss: 0.0237 - accuracy: 0.9915 - val_loss: 0.0399 - val_accuracy: 0.9871\n",
      "Epoch 924/1000\n",
      "11512/11512 [==============================] - 3s 256us/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0409 - val_accuracy: 0.9882\n",
      "Epoch 925/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0403 - val_accuracy: 0.9889\n",
      "Epoch 926/1000\n",
      "11512/11512 [==============================] - 4s 310us/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0396 - val_accuracy: 0.9892\n",
      "Epoch 927/1000\n",
      "11512/11512 [==============================] - 4s 337us/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
      "Epoch 928/1000\n",
      "11512/11512 [==============================] - 4s 313us/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0419 - val_accuracy: 0.9854\n",
      "Epoch 929/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0410 - val_accuracy: 0.9878\n",
      "Epoch 930/1000\n",
      "11512/11512 [==============================] - 3s 258us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0397 - val_accuracy: 0.9885\n",
      "Epoch 931/1000\n",
      "11512/11512 [==============================] - 3s 223us/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 932/1000\n",
      "11512/11512 [==============================] - 4s 306us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0381 - val_accuracy: 0.9882\n",
      "Epoch 933/1000\n",
      "11512/11512 [==============================] - 3s 279us/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0411 - val_accuracy: 0.9882\n",
      "Epoch 934/1000\n",
      "11512/11512 [==============================] - 4s 380us/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.0383 - val_accuracy: 0.9889\n",
      "Epoch 935/1000\n",
      "11512/11512 [==============================] - 3s 300us/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.0406 - val_accuracy: 0.9875\n",
      "Epoch 936/1000\n",
      "11512/11512 [==============================] - 4s 355us/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0415 - val_accuracy: 0.9882\n",
      "Epoch 937/1000\n",
      "11512/11512 [==============================] - 4s 355us/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0409 - val_accuracy: 0.9882\n",
      "Epoch 938/1000\n",
      "11512/11512 [==============================] - 4s 356us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0406 - val_accuracy: 0.9885\n",
      "Epoch 939/1000\n",
      "11512/11512 [==============================] - 4s 380us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0410 - val_accuracy: 0.9871\n",
      "Epoch 940/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0235 - accuracy: 0.9918 - val_loss: 0.0422 - val_accuracy: 0.9871\n",
      "Epoch 941/1000\n",
      "11512/11512 [==============================] - 3s 266us/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0400 - val_accuracy: 0.9899\n",
      "Epoch 942/1000\n",
      "11512/11512 [==============================] - 3s 261us/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.0407 - val_accuracy: 0.9875\n",
      "Epoch 943/1000\n",
      "11512/11512 [==============================] - 3s 274us/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0416 - val_accuracy: 0.9878\n",
      "Epoch 944/1000\n",
      "11512/11512 [==============================] - 3s 267us/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.0383 - val_accuracy: 0.9892\n",
      "Epoch 945/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0433 - val_accuracy: 0.9871\n",
      "Epoch 946/1000\n",
      "11512/11512 [==============================] - 3s 259us/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0391 - val_accuracy: 0.9896\n",
      "Epoch 947/1000\n",
      "11512/11512 [==============================] - 3s 266us/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.0382 - val_accuracy: 0.9882\n",
      "Epoch 948/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
      "Epoch 949/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0427 - val_accuracy: 0.9875\n",
      "Epoch 950/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0383 - val_accuracy: 0.9892\n",
      "Epoch 951/1000\n",
      "11512/11512 [==============================] - 3s 281us/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
      "Epoch 952/1000\n",
      "11512/11512 [==============================] - 3s 282us/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0410 - val_accuracy: 0.9885\n",
      "Epoch 953/1000\n",
      "11512/11512 [==============================] - 3s 226us/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0403 - val_accuracy: 0.9871\n",
      "Epoch 954/1000\n",
      "11512/11512 [==============================] - 3s 278us/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0424 - val_accuracy: 0.9878\n",
      "Epoch 955/1000\n",
      "11512/11512 [==============================] - 3s 261us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0397 - val_accuracy: 0.9875\n",
      "Epoch 956/1000\n",
      "11512/11512 [==============================] - 3s 264us/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0407 - val_accuracy: 0.9878\n",
      "Epoch 957/1000\n",
      "11512/11512 [==============================] - 3s 288us/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0444 - val_accuracy: 0.9851\n",
      "Epoch 958/1000\n",
      "11512/11512 [==============================] - 3s 294us/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0377 - val_accuracy: 0.9878\n",
      "Epoch 959/1000\n",
      "11512/11512 [==============================] - 4s 322us/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.0398 - val_accuracy: 0.9871\n",
      "Epoch 960/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0385 - val_accuracy: 0.9889\n",
      "Epoch 961/1000\n",
      "11512/11512 [==============================] - 3s 280us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0389 - val_accuracy: 0.9875\n",
      "Epoch 962/1000\n",
      "11512/11512 [==============================] - 4s 316us/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0396 - val_accuracy: 0.9871\n",
      "Epoch 963/1000\n",
      "11512/11512 [==============================] - 4s 378us/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.0482 - val_accuracy: 0.9878\n",
      "Epoch 964/1000\n",
      "11512/11512 [==============================] - 5s 457us/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.0402 - val_accuracy: 0.9871\n",
      "Epoch 965/1000\n",
      "11512/11512 [==============================] - 5s 424us/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.0392 - val_accuracy: 0.9885\n",
      "Epoch 966/1000\n",
      "11512/11512 [==============================] - 5s 397us/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0379 - val_accuracy: 0.9889\n",
      "Epoch 967/1000\n",
      "11512/11512 [==============================] - 4s 355us/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.0421 - val_accuracy: 0.9882\n",
      "Epoch 968/1000\n",
      "11512/11512 [==============================] - 4s 309us/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
      "Epoch 969/1000\n",
      "11512/11512 [==============================] - 4s 338us/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0408 - val_accuracy: 0.9885\n",
      "Epoch 970/1000\n",
      "11512/11512 [==============================] - 4s 330us/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0426 - val_accuracy: 0.9861\n",
      "Epoch 971/1000\n",
      "11512/11512 [==============================] - 3s 304us/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 972/1000\n",
      "11512/11512 [==============================] - 3s 298us/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0403 - val_accuracy: 0.9882\n",
      "Epoch 973/1000\n",
      "11512/11512 [==============================] - 3s 299us/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
      "Epoch 974/1000\n",
      "11512/11512 [==============================] - 3s 253us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0381 - val_accuracy: 0.9899\n",
      "Epoch 975/1000\n",
      "11512/11512 [==============================] - 2s 201us/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0407 - val_accuracy: 0.9878\n",
      "Epoch 976/1000\n",
      "11512/11512 [==============================] - 2s 206us/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
      "Epoch 977/1000\n",
      "11512/11512 [==============================] - 4s 333us/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0389 - val_accuracy: 0.9885\n",
      "Epoch 978/1000\n",
      "11512/11512 [==============================] - 4s 357us/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0376 - val_accuracy: 0.9896\n",
      "Epoch 979/1000\n",
      "11512/11512 [==============================] - 4s 372us/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0458 - val_accuracy: 0.9882\n",
      "Epoch 980/1000\n",
      "11512/11512 [==============================] - 4s 379us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0401 - val_accuracy: 0.9885\n",
      "Epoch 981/1000\n",
      "11512/11512 [==============================] - 5s 406us/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.0387 - val_accuracy: 0.9882\n",
      "Epoch 982/1000\n",
      "11512/11512 [==============================] - 5s 411us/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0401 - val_accuracy: 0.9871\n",
      "Epoch 983/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 984/1000\n",
      "11512/11512 [==============================] - 3s 269us/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.0395 - val_accuracy: 0.9878\n",
      "Epoch 985/1000\n",
      "11512/11512 [==============================] - 3s 292us/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.0378 - val_accuracy: 0.9899\n",
      "Epoch 986/1000\n",
      "11512/11512 [==============================] - 3s 291us/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0463 - val_accuracy: 0.9851\n",
      "Epoch 987/1000\n",
      "11512/11512 [==============================] - 4s 317us/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0396 - val_accuracy: 0.9878\n",
      "Epoch 988/1000\n",
      "11512/11512 [==============================] - 3s 283us/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0412 - val_accuracy: 0.9868\n",
      "Epoch 989/1000\n",
      "11512/11512 [==============================] - 3s 260us/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0415 - val_accuracy: 0.9885\n",
      "Epoch 990/1000\n",
      "11512/11512 [==============================] - 3s 245us/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0405 - val_accuracy: 0.9858\n",
      "Epoch 991/1000\n",
      "11512/11512 [==============================] - 3s 286us/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0419 - val_accuracy: 0.9875\n",
      "Epoch 992/1000\n",
      "11512/11512 [==============================] - 3s 273us/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
      "Epoch 993/1000\n",
      "11512/11512 [==============================] - 4s 308us/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0403 - val_accuracy: 0.9875\n",
      "Epoch 994/1000\n",
      "11512/11512 [==============================] - 3s 289us/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.0385 - val_accuracy: 0.9882\n",
      "Epoch 995/1000\n",
      "11512/11512 [==============================] - 3s 295us/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
      "Epoch 996/1000\n",
      "11512/11512 [==============================] - 4s 318us/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0424 - val_accuracy: 0.9875\n",
      "Epoch 997/1000\n",
      "11512/11512 [==============================] - 3s 275us/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0413 - val_accuracy: 0.9871\n",
      "Epoch 998/1000\n",
      "11512/11512 [==============================] - 3s 235us/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
      "Epoch 999/1000\n",
      "11512/11512 [==============================] - 3s 296us/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0387 - val_accuracy: 0.9882\n",
      "Epoch 1000/1000\n",
      "11512/11512 [==============================] - 3s 255us/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0406 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model()\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1000, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6168/6168 [==============================] - 0s 30us/step\n",
      "Loss 0.025931, Accuracy 0.991732\n",
      "Loss 0.027803, Accuracy 0.990759\n",
      "Loss 0.029171, Accuracy 0.991083\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_3, test_acc_3 = model3.evaluate(X_test, y_test)\n",
    "\n",
    "print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))\n",
    "plot_model(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3['loss'], label='Train')\n",
    "plt.plot(history3['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most relevant arguments are:\n",
    "\n",
    "* monitor: quantity to be monitored\n",
    "* patience: number of epochs with no improvement after which training will be stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11507 samples, validate on 2877 samples\n",
      "Epoch 1/100\n",
      "11507/11507 [==============================] - 3s 274us/step - loss: 0.1682 - accuracy: 0.9629 - val_loss: 0.0578 - val_accuracy: 0.9871\n",
      "Epoch 2/100\n",
      "11507/11507 [==============================] - 3s 223us/step - loss: 0.0388 - accuracy: 0.9917 - val_loss: 0.0531 - val_accuracy: 0.9871\n",
      "Epoch 3/100\n",
      "11507/11507 [==============================] - 2s 185us/step - loss: 0.0362 - accuracy: 0.9919 - val_loss: 0.0523 - val_accuracy: 0.9871\n",
      "Epoch 4/100\n",
      "11507/11507 [==============================] - 2s 212us/step - loss: 0.0354 - accuracy: 0.9919 - val_loss: 0.0484 - val_accuracy: 0.9871\n",
      "Epoch 5/100\n",
      "11507/11507 [==============================] - 3s 247us/step - loss: 0.0347 - accuracy: 0.9918 - val_loss: 0.0471 - val_accuracy: 0.9871\n",
      "Epoch 6/100\n",
      "11507/11507 [==============================] - 2s 189us/step - loss: 0.0343 - accuracy: 0.9919 - val_loss: 0.0479 - val_accuracy: 0.9871\n",
      "Epoch 7/100\n",
      "11507/11507 [==============================] - 2s 140us/step - loss: 0.0340 - accuracy: 0.9919 - val_loss: 0.0462 - val_accuracy: 0.9868\n",
      "Epoch 8/100\n",
      "11507/11507 [==============================] - 2s 147us/step - loss: 0.0336 - accuracy: 0.9919 - val_loss: 0.0458 - val_accuracy: 0.9868\n",
      "Epoch 9/100\n",
      "11507/11507 [==============================] - 2s 160us/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 0.0446 - val_accuracy: 0.9868\n",
      "Epoch 10/100\n",
      "11507/11507 [==============================] - 2s 191us/step - loss: 0.0329 - accuracy: 0.9919 - val_loss: 0.0458 - val_accuracy: 0.9871\n",
      "Epoch 11/100\n",
      "11507/11507 [==============================] - 2s 155us/step - loss: 0.0327 - accuracy: 0.9920 - val_loss: 0.0457 - val_accuracy: 0.9871\n",
      "Epoch 12/100\n",
      "11507/11507 [==============================] - 2s 178us/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 0.0456 - val_accuracy: 0.9871\n",
      "Epoch 13/100\n",
      "11507/11507 [==============================] - 2s 171us/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 0.0462 - val_accuracy: 0.9871\n",
      "Epoch 14/100\n",
      "11507/11507 [==============================] - 2s 198us/step - loss: 0.0324 - accuracy: 0.9917 - val_loss: 0.0466 - val_accuracy: 0.9871\n",
      "Epoch 15/100\n",
      "11507/11507 [==============================] - 3s 244us/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.0449 - val_accuracy: 0.9871\n",
      "Epoch 16/100\n",
      "11507/11507 [==============================] - 2s 195us/step - loss: 0.0320 - accuracy: 0.9920 - val_loss: 0.0465 - val_accuracy: 0.9871\n",
      "Epoch 17/100\n",
      "11507/11507 [==============================] - 2s 191us/step - loss: 0.0320 - accuracy: 0.9919 - val_loss: 0.0444 - val_accuracy: 0.9871\n",
      "Epoch 18/100\n",
      "11507/11507 [==============================] - 3s 236us/step - loss: 0.0320 - accuracy: 0.9920 - val_loss: 0.0446 - val_accuracy: 0.9871\n",
      "Epoch 19/100\n",
      "11507/11507 [==============================] - 2s 158us/step - loss: 0.0317 - accuracy: 0.9919 - val_loss: 0.0433 - val_accuracy: 0.9868\n",
      "Epoch 20/100\n",
      "11507/11507 [==============================] - 2s 191us/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 0.0432 - val_accuracy: 0.9868\n",
      "Epoch 21/100\n",
      "11507/11507 [==============================] - 2s 195us/step - loss: 0.0316 - accuracy: 0.9919 - val_loss: 0.0443 - val_accuracy: 0.9871\n",
      "Epoch 22/100\n",
      "11507/11507 [==============================] - 2s 159us/step - loss: 0.0317 - accuracy: 0.9919 - val_loss: 0.0436 - val_accuracy: 0.9868\n",
      "Epoch 23/100\n",
      "11507/11507 [==============================] - 2s 165us/step - loss: 0.0316 - accuracy: 0.9919 - val_loss: 0.0422 - val_accuracy: 0.9868\n",
      "Epoch 24/100\n",
      "11507/11507 [==============================] - 2s 161us/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.0431 - val_accuracy: 0.9871\n",
      "Epoch 25/100\n",
      "11507/11507 [==============================] - 2s 157us/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.0439 - val_accuracy: 0.9871\n",
      "Epoch 26/100\n",
      "11507/11507 [==============================] - 2s 171us/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 0.0423 - val_accuracy: 0.9871\n",
      "Epoch 27/100\n",
      "11507/11507 [==============================] - 1s 120us/step - loss: 0.0314 - accuracy: 0.9917 - val_loss: 0.0457 - val_accuracy: 0.9868\n",
      "Epoch 28/100\n",
      "11507/11507 [==============================] - 1s 120us/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.0425 - val_accuracy: 0.9868\n",
      "Epoch 29/100\n",
      "11507/11507 [==============================] - 1s 127us/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 0.0425 - val_accuracy: 0.9868\n",
      "Epoch 30/100\n",
      "11507/11507 [==============================] - 2s 161us/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 0.0429 - val_accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "11507/11507 [==============================] - 2s 146us/step - loss: 0.0311 - accuracy: 0.9920 - val_loss: 0.0428 - val_accuracy: 0.9868\n",
      "Epoch 32/100\n",
      "11507/11507 [==============================] - 2s 139us/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.0419 - val_accuracy: 0.9868\n",
      "Epoch 33/100\n",
      "11507/11507 [==============================] - 2s 131us/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0425 - val_accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "11507/11507 [==============================] - 2s 132us/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0434 - val_accuracy: 0.9868\n",
      "Epoch 35/100\n",
      "11507/11507 [==============================] - 2s 147us/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.0422 - val_accuracy: 0.9868\n",
      "Epoch 36/100\n",
      "11507/11507 [==============================] - 2s 138us/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.0423 - val_accuracy: 0.9864\n",
      "Epoch 37/100\n",
      "11507/11507 [==============================] - 2s 131us/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.0452 - val_accuracy: 0.9871\n",
      "Epoch 38/100\n",
      "11507/11507 [==============================] - 1s 127us/step - loss: 0.0310 - accuracy: 0.9918 - val_loss: 0.0438 - val_accuracy: 0.9868\n",
      "Epoch 39/100\n",
      "11507/11507 [==============================] - 1s 129us/step - loss: 0.0309 - accuracy: 0.9919 - val_loss: 0.0443 - val_accuracy: 0.9868\n",
      "Epoch 40/100\n",
      "11507/11507 [==============================] - 2s 154us/step - loss: 0.0305 - accuracy: 0.9921 - val_loss: 0.0420 - val_accuracy: 0.9868\n",
      "Epoch 41/100\n",
      "11507/11507 [==============================] - 2s 144us/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.0454 - val_accuracy: 0.9868\n",
      "Epoch 42/100\n",
      "11507/11507 [==============================] - 2s 157us/step - loss: 0.0308 - accuracy: 0.9919 - val_loss: 0.0423 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10)\n",
    "mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model4 = build_model()\n",
    "history4 = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                      batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6168/6168 [==============================] - 0s 60us/step\n",
      "Loss 0.034048, Accuracy 0.990921\n"
     ]
    }
   ],
   "source": [
    "test_loss_4, test_acc_4 = model4.evaluate(X_test, y_test)\n",
    "\n",
    "#print('Loss %f, Accuracy %f' % (test_loss_1, test_acc_1))\n",
    "#print('Loss %f, Accuracy %f' % (test_loss_2, test_acc_2))\n",
    "#print('Loss %f, Accuracy %f' % (test_loss_3, test_acc_3))\n",
    "print('Loss %f, Accuracy %f' % (test_loss_4, test_acc_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4['loss'], label='Train')\n",
    "plt.plot(history4['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def build_L2_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=1\n",
    "    model.add(Dense(35, activation='relu', input_shape=(n_feature,), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(21, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(7, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ModelCheckpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2a9179c228ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_model_L2.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mL2_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_L2_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m h_L2 = L2_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n\u001b[0;32m      5\u001b[0m                     batch_size=10, callbacks=[es,mc]).history\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ModelCheckpoint' is not defined"
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_L2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "L2_model = build_L2_model()\n",
    "h_L2 = L2_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, \n",
    "                    batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "def build_DROPOUT_model():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    h_dim=100\n",
    "    model.add(Dense(h_dim, activation='relu', input_shape=(n_feature,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(h_dim, activation='relu'))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-0966f4bbece6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mDROPOUT_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_DROPOUT_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m h_DROPOUT = DROPOUT_model.fit(X_train, y_train, validation_data=(X_val, y_val), \n\u001b[1;32m----> 5\u001b[1;33m                               epochs=100, batch_size=10, callbacks=[es,mc]).history\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                     **self._function_kwargs)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   1452\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m                 \u001b[0m_raise_invalid_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   1419\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m                                         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m   1422\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_metric'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m         self._metrics_function = theano.function(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1837\u001b[0m                   \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m                   \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m                   name=name)\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchange_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_test_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys, name)\u001b[0m\n\u001b[0;32m   1517\u001b[0m                         optimizer, inputs, outputs)\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1519\u001b[1;33m                     \u001b[0moptimizer_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    249\u001b[0m                     \u001b[0mnb_nodes_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                     \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m                     \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph, start_from)\u001b[0m\n\u001b[0;32m   2141\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2142\u001b[0m                 \u001b[0mcurrent_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2143\u001b[1;33m                 \u001b[0mnb\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2144\u001b[0m             \u001b[0mloop_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\opt.py\u001b[0m in \u001b[0;36mprocess_node\u001b[1;34m(self, fgraph, node, lopt)\u001b[0m\n\u001b[0;32m   2072\u001b[0m             fgraph.replace_all_validate_remove(repl_pairs,\n\u001b[0;32m   2073\u001b[0m                                                \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2074\u001b[1;33m                                                remove=remove)\n\u001b[0m\u001b[0;32m   2075\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2076\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\toolbox.py\u001b[0m in \u001b[0;36mreplace_all_validate_remove\u001b[1;34m(self, fgraph, replacements, remove, reason, warn)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \"\"\"\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[0mchk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_all_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplacements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_removed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mremove\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\toolbox.py\u001b[0m in \u001b[0;36mreplace_all_validate\u001b[1;34m(self, fgraph, replacements, reason, verbose)\u001b[0m\n\u001b[0;32m    541\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrevert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\toolbox.py\u001b[0m in \u001b[0;36mvalidate_\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mcf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\fg.py\u001b[0m in \u001b[0;36mexecute_callbacks\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mtf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_callbacks_times\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_callbacks_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\destroyhandler.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    653\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mapp_err_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m                 \u001b[0mords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morderings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_contains_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInconsistencyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dependency graph contains cycles\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\destroyhandler.py\u001b[0m in \u001b[0;36morderings\u001b[1;34m(self, fgraph, ordered)\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mroot_clients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;31m# for each destroyed input...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0moutput_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_idx_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m                     \u001b[0mdestroyed_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_idx_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m                     \u001b[0mdestroyed_variable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdestroyed_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint('best_model_DROPOUT.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "DROPOUT_model = build_DROPOUT_model()\n",
    "h_DROPOUT = DROPOUT_model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                              epochs=100, batch_size=10, callbacks=[es,mc]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6168/6168 [==============================] - 2s 261us/step\n",
      "6168/6168 [==============================] - 3s 530us/step\n",
      "6168/6168 [==============================] - 5s 787us/step\n"
     ]
    }
   ],
   "source": [
    "# laod best models and test them\n",
    "from keras.models import load_model\n",
    "\n",
    "best_NOREG_model = load_model('best_model_NOREG.h5')\n",
    "best_L2_model = load_model('best_model_L2.h5')\n",
    "best_DROPOUT_model = load_model('best_model_DROPOUT.h5')\n",
    "\n",
    "loss_NOREG, acc_NOREG = best_NOREG_model.evaluate(X_test, y_test)\n",
    "loss_L2, acc_L2 = best_L2_model.evaluate(X_test, y_test)\n",
    "loss_DROPOUT, acc_DROPOUT = best_DROPOUT_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.034552, Accuracy 0.990759\n",
      "Loss 0.169186, Accuracy 0.971628\n",
      "Loss 0.144954, Accuracy 0.000000\n"
     ]
    }
   ],
   "source": [
    "print('Loss %f, Accuracy %f' % (loss_NOREG, acc_NOREG))\n",
    "print('Loss %f, Accuracy %f' % (loss_L2, acc_L2))\n",
    "print('Loss %f, Accuracy %f' % (loss_DROPOUT, acc_DROPOUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers=2, h_dim=5, activation='relu', optimizer='adam'):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    n_feature = X_train.shape[1]\n",
    "    \n",
    "    model.add(Dense(h_dim, activation=activation, input_shape=(n_feature,)))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(h_dim, activation=activation))\n",
    "    #linear activation\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = [1, 2, 3]\n",
    "h_dim = [7, 15, 21]\n",
    "activation = ['relu', 'tanh']\n",
    "optimizer = ['adagrad', 'adam']\n",
    "params = dict(optimizer=optimizer, n_layers=n_layers, h_dim=h_dim, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14384, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4795/4795 [==============================] - 1s 139us/step\n",
      "4795/4795 [==============================] - 2s 380us/step\n",
      "4794/4794 [==============================] - 2s 400us/step\n",
      "4795/4795 [==============================] - 4s 863us/step\n",
      "4795/4795 [==============================] - 2s 382us/step\n",
      "4794/4794 [==============================] - 4s 829us/step\n",
      "4795/4795 [==============================] - 5s 1ms/step\n",
      "4795/4795 [==============================] - 3s 590us/step\n",
      "4794/4794 [==============================] - 3s 662us/step\n",
      "4795/4795 [==============================] - 4s 786us/step\n",
      "4795/4795 [==============================] - 0s 45us/step\n",
      "4794/4794 [==============================] - 3s 588us/step\n",
      "4795/4795 [==============================] - 0s 34us/step\n",
      "4795/4795 [==============================] - 12s 2ms/step\n",
      "4794/4794 [==============================] - 9s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "rnd = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=5, cv=3)\n",
    "rnd_result = rnd.fit(X, y, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.282419 using {'optimizer': 'adagrad', 'n_layers': 3, 'h_dim': 7, 'activation': 'tanh'}\n",
      "5.284746 (5.092191) with: {'optimizer': 'adam', 'n_layers': 1, 'h_dim': 7, 'activation': 'tanh'}\n",
      "6.511088 (3.974887) with: {'optimizer': 'adam', 'n_layers': 2, 'h_dim': 15, 'activation': 'relu'}\n",
      "1.364287 (1.759934) with: {'optimizer': 'adam', 'n_layers': 2, 'h_dim': 15, 'activation': 'tanh'}\n",
      "1.539162 (1.640737) with: {'optimizer': 'adagrad', 'n_layers': 2, 'h_dim': 15, 'activation': 'tanh'}\n",
      "0.282419 (0.174601) with: {'optimizer': 'adagrad', 'n_layers': 3, 'h_dim': 7, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (-rnd_result.best_score_, rnd_result.best_params_))\n",
    "means = rnd_result.cv_results_['mean_test_score']\n",
    "stds = rnd_result.cv_results_['std_test_score']\n",
    "params = rnd_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (-mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6168/6168 [==============================] - 16s 3ms/step\n",
      "Loss 5.686455, Accuracy 0.332523\n"
     ]
    }
   ],
   "source": [
    "clf = rnd_result.best_estimator_.model\n",
    "\n",
    "loss, acc = clf.evaluate(X_test, y_test)\n",
    "print('Loss %f, Accuracy %f' % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11507 samples, validate on 2877 samples\n",
      "Epoch 1/100\n",
      "11507/11507 [==============================] - 4s 373us/step - loss: 0.2106 - accuracy: 0.6246 - val_loss: 0.1220 - val_accuracy: 0.5850\n",
      "Epoch 2/100\n",
      "11507/11507 [==============================] - 4s 345us/step - loss: 0.0843 - accuracy: 0.5667 - val_loss: 0.0961 - val_accuracy: 0.5728\n",
      "Epoch 3/100\n",
      "11507/11507 [==============================] - 4s 389us/step - loss: 0.0834 - accuracy: 0.5511 - val_loss: 0.1269 - val_accuracy: 0.5280\n",
      "Epoch 4/100\n",
      "11507/11507 [==============================] - 4s 368us/step - loss: 0.0817 - accuracy: 0.5017 - val_loss: 0.0890 - val_accuracy: 0.4793\n",
      "Epoch 5/100\n",
      " 4660/11507 [===========>..................] - ETA: 2s - loss: 0.0774 - accuracy: 0.4524 ETA: 3s - loss: 0"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-b02e73a77d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistoryBest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mbatch_hook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mbatch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \"\"\"\n\u001b[0;32m    365\u001b[0m         \u001b[1;31m# For backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "historyBest = clf.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=10).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyBest['loss'], label='Train')\n",
    "plt.plot(historyBest['val_loss'], label='Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
